{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0Okrzi9p4NDR99koOEv64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day19_MLP_in_PyTorch_Part2_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day19\n",
        "## Building a Simple MLP using PyTorch Library\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to PyTorch\n",
        "\n",
        "We can use PyTorch Framework to build and train MLPs and other neural networks such as CNN, RNN, Transformers. Let's learn the basics of PyTorch."
      ],
      "metadata": {
        "id": "9r7g0RAbrLTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "v1CBrgItrNzM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Put the Model on Training Device (GPU or CPU)__\n",
        "We want to accelerate the training process using graphical processing unit (GPU). Fortunately, in Colab we can access for GPU. You need to enable it from _Runtime-->Change runtime type-->GPU or TPU_"
      ],
      "metadata": {
        "id": "3awNnb-YtDpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "# if it prints 'cuda' then colab is running using GPU device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KRrGdHZtKK4",
        "outputId": "83a393eb-8413-40e2-fd35-425123bbccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Group activity__\n",
        "Make another simple MLP with the specifications below and perform the 'Forward Pass' of the MLP."
      ],
      "metadata": {
        "id": "Ydjmn67Q3h5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 1 random samples of (x1, x2, x3) for the network\n",
        "torch.manual_seed(0)                      # for reproducibility\n",
        "random_X = torch.randn(1,3)"
      ],
      "metadata": {
        "id": "3D6Am3aSkTqq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0) # for reproducibility\n",
        "# Q1: how many hidden layers should be there? (depth)\n",
        "# answer: there is only 1 hidden layer\n",
        "num_of_hidden_layer = 1\n",
        "\n",
        "\n",
        "# Q2: how many neurons should be in each layer? (width)\n",
        "# answer: there are 3 neurons in the input  layer\n",
        "#         there are 4 neurons in the hidden layer\n",
        "#         there are 1 neurons in the output layer\n",
        "num_of_neurons_input_layer  =\n",
        "num_of_neurons_hidden_layer =\n",
        "num_of_neurons_output_layer =\n",
        "\n",
        "\n",
        "# Q3 how many dense connections should be there in between each adjacent layers\n",
        "# answer: there should be ?x? dense connnections (between input  layer and hidden layer: dense_connections_W1)\n",
        "#         there should be ?x1 dense connnections (between hidden layer and output layer: dense_connections_W2)\n",
        "# add the bias terms for all the layers except input layer\n",
        "\n",
        "\n",
        "# Q4: what should the activation be at each of the intermediate layers?\n",
        "# answer: let use sigmoid() activation function in the hidden layer\n",
        "\n",
        "# Q5: what should be activation of the final layer (let's assume we are using a binary classification task for which sigmoid activation is used)\n"
      ],
      "metadata": {
        "id": "GhtxxDoZ3ev6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f527a293-3972-4d35-f777-e22a6670810a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3173836288.py, line 11)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3173836288.py\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    num_of_neurons_input_layer  =\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# do the Forward Pass in Multilayer Perceptron (MLP)\n",
        "# Step 1 -- input to hidden layer\n",
        "\n",
        "\n",
        "# Step 2 -- hidden to output layer"
      ],
      "metadata": {
        "id": "UIY0ndvQkGx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete for student\n",
        "\n",
        "torch.manual_seed(0) # for reproducibility\n",
        "# Q1: how many hidden layers should be there? (depth)\n",
        "# answer: there is only 1 hidden layer\n",
        "num_of_hidden_layer = 1\n",
        "\n",
        "\n",
        "# Q2: how many neurons should be in each layer? (width)\n",
        "# answer: there are 3 neurons in the input  layer\n",
        "#         there are 4 neurons in the hidden layer\n",
        "#         there are 1 neurons in the output layer\n",
        "num_of_neurons_input_layer  = 3\n",
        "num_of_neurons_hidden_layer = 4\n",
        "num_of_neurons_output_layer = 1\n",
        "\n",
        "\n",
        "# Q3 how many dense connections should be there in between each adjacent layers\n",
        "# answer: there should be 3x4 dense connnections (between input  layer and hidden layer: dense_connections_W1)\n",
        "#         there should be 4x1 dense connnections (between hidden layer and output layer: dense_connections_W2)\n",
        "dense_connections_W1 = torch.rand(num_of_neurons_input_layer, num_of_neurons_hidden_layer)\n",
        "dense_connections_W2 = torch.rand(num_of_neurons_hidden_layer, num_of_neurons_output_layer)\n",
        "# add the bias terms for all the layers except input layer\n",
        "bias_terms_hidden = torch.rand(num_of_neurons_hidden_layer)\n",
        "bias_terms_output = torch.rand(num_of_neurons_output_layer)\n",
        "\n",
        "# Q4: what should the activation be at each of the intermediate layers?\n",
        "# answer: let use sigmoid() activation function in the hidden layer\n",
        "sigmoid_activation_hidden = nn.Sigmoid()\n",
        "\n",
        "# Q5: what should be activation of the final layer (let's assume we are using a binary classification task for which sigmoid activation is used)\n",
        "sigmoid_activation_output = nn.Sigmoid()\n"
      ],
      "metadata": {
        "id": "DUmSBDx_jGy0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do a Forward Pass in Multilayer Perceptron (MLP)\n",
        "\n",
        "# Step 1 -- input to hidden layer\n",
        "matrix_mult_X_and_W1 = torch.matmul(random_X[0,:], dense_connections_W1) + bias_terms_hidden\n",
        "output_hidden_layer = sigmoid_activation_hidden(matrix_mult_X_and_W1)\n",
        "\n",
        "# Step 2 -- hidden to output layer\n",
        "matrix_mult_hidden_and_W2 = torch.matmul(output_hidden_layer, dense_connections_W2) + bias_terms_output\n",
        "final_output = sigmoid_activation_output(matrix_mult_hidden_and_W2)\n",
        "\n",
        "print('output of final layer: \\n', final_output.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3MkCydLkF43",
        "outputId": "7e1ec034-428a-4410-b735-78db053f65e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output of final layer: \n",
            " [0.74611795]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PjU46rJrpQZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Linear Layers using PyTorch"
      ],
      "metadata": {
        "id": "fPGYgJT1pfRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a linear layer**"
      ],
      "metadata": {
        "id": "dNxXEEFkpi7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)                    # for reproducibility\n",
        "# construction of a linear layer\n",
        "input_layer_1 = nn.Linear(2, 4)"
      ],
      "metadata": {
        "id": "LVRZfQeVptyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inspecting the weights of a linear layer**"
      ],
      "metadata": {
        "id": "vMRLvywQvn6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of the linear layer\n",
        "print(f'Weights: \\n{input_layer_1.weight.data}')\n",
        "\n",
        "# Print the biases of the linear layer (if they exist)\n",
        "print(f'Biases: \\n{input_layer_1.bias.data}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVDaVYuGvrhb",
        "outputId": "7ebae9b2-b98c-4a32-f904-9bc09f65ac0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "tensor([[ 0.1622, -0.1683],\n",
            "        [ 0.1939, -0.0361],\n",
            "        [ 0.3021,  0.1683],\n",
            "        [-0.0813, -0.5717]])\n",
            "Biases: \n",
            "tensor([ 0.1614, -0.6260,  0.0929,  0.0470])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's generate a random input for our linear layer and plug it into our layer**"
      ],
      "metadata": {
        "id": "Mvhdn_kSvyvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 1\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output = input_layer_1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9r5YemSXv41r",
        "outputId": "17b65d3c-90ae-44fd-ea33-a0706a856f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 0.39229682 -0.22356401]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.26269433 -0.5418887   0.17379826  0.14291514]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Challenge #1**\n",
        "Create a new Linear layer with the following structure:\n",
        "\n",
        "> The first layer has 2 input nodes and 16 output nodes.\n"
      ],
      "metadata": {
        "id": "rhF9xI8Dx06c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)                    # for reproducibility\n",
        "# construction of a linear layer\n",
        "# your code here"
      ],
      "metadata": {
        "id": "d_pQTklW6Esu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)                    # for reproducibility\n",
        "# construction of a linear layer\n",
        "input_layer_1 = nn.Linear(2, 16)"
      ],
      "metadata": {
        "id": "yAr2HsYZv4Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Challenge #2**\n",
        "\n",
        "> generate a random input for our linear layer and apply forward pass through the network. Print out the resulting output layer values. How many numbers do you expect?"
      ],
      "metadata": {
        "id": "4i94s0CiyRJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0) # for reproducibility\n",
        "# your code here"
      ],
      "metadata": {
        "id": "gqeVmz5_6Lny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 1\n",
        "random_input = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "output = input_layer_1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtFN8u33yT32",
        "outputId": "a7b0a047-6428-4884-8b87-499103bfbe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 1.5409961 -0.2934289]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.46574774  0.7747904   0.45092157 -0.28162462  0.7432405  -0.1420176\n",
            "  -0.56590974 -0.40096116  0.36150265 -1.2736461  -0.751479    0.04142258\n",
            "  -0.01777191  0.41104984 -0.21710443 -0.8239027 ]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2"
      ],
      "metadata": {
        "id": "ykFebK-uQvMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's add an activation function such as *ReLu(), tanh(), or sigmoid()* after your linear layer and run the experiment again to see how it changes the outputs.**"
      ],
      "metadata": {
        "id": "NrlG1w0LjlGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a linear layer\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "input_linear_layer = nn.Linear(2, 4)  # linear transformation module (input=2, output=4)\n",
        "\n",
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "number_of_samples = 1\n",
        "random_X = torch.randn(number_of_samples, 2)\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "sigmoid_activation = nn.Sigmoid() #this is like a call to a constructor\n",
        "tanh_activation = nn.Tanh()\n",
        "relu_activation  = nn.ReLU()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhpZlUGPjqSc",
        "outputId": "6b4c82e1-b14d-4195-bbd4-740972c71a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[0.57310677 0.54094744]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sigmoid()**"
      ],
      "metadata": {
        "id": "2F0pp1-9opXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: apply forward pass through the network\n",
        "output = input_linear_layer(random_X)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "\n",
        "output_after_activation = sigmoid_activation(output) ## apply the activation function!\n",
        "print('Sigmoid activation value: ')\n",
        "print(output_after_activation.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUn_yTxfqJrP",
        "outputId": "7f9a9024-233e-419a-97a0-5ae9bcbe42d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output layer value: \n",
            "[[ 0.1633755  -0.5344403   0.3571151  -0.30882734]]\n",
            "Sigmoid activation value: \n",
            "[[0.54075325 0.36948186 0.5883419  0.42340097]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise #4a : apply the Tanh() activation functions to the above network**\n",
        "\n",
        "# **Exercise #4b : apply the ReLU() activation function to the above network**\n",
        "\n",
        "Which activation function gives the result of all non-negative values?\n"
      ],
      "metadata": {
        "id": "RRnWGTs6pDCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tanh()\n",
        "output = input_linear_layer(random_X)\n",
        "output_after_activation = tanh_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Tanh activation value: ')\n",
        "print(output_after_activation.data.numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_sS4Gj7peun",
        "outputId": "b1a6b585-cc75-4490-ebce-1fd0dc0d9cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output layer value: \n",
            "[[ 0.1633755  -0.5344403   0.3571151  -0.30882734]]\n",
            "Tanh activation value: \n",
            "[[ 0.16193727 -0.48876795  0.3426704  -0.2993699 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# relu()\n",
        "output = input_linear_layer(random_X)\n",
        "output_after_activation = tanh_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('ReLU activation value: ')\n",
        "print(output_after_activation.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92BlGdvbqXj-",
        "outputId": "ce246036-8d51-4ac2-dcb3-e98367bb18e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output layer value: \n",
            "[[ 0.1633755  -0.5344403   0.3571151  -0.30882734]]\n",
            "ReLU activation value: \n",
            "[[ 0.16193727 -0.48876795  0.3426704  -0.2993699 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU()\n",
        "output = input_linear_layer(random_X)\n",
        "output_after_activation = relu_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Sigmoid activation value: ')\n",
        "print(output_after_activation.data.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlw2wXxLqc62",
        "outputId": "339a126d-3878-4da0-d378-f62f8af2a327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output layer value: \n",
            "[[ 0.26269433 -0.5418887   0.17379826  0.14291514]]\n",
            "Sigmoid activation value: \n",
            "[[0.26269433 0.         0.17379826 0.14291514]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build the simple 1-hidden layer feedforward neural network!**\n",
        "\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/mlp_toy_examle_wo_weights.png\" width=400/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "8jNPsQTlsyjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make the simple 1-Hidden layer feedforwrd neural network from the lecture slides\n",
        "# only with ReLU activation for hidden layer, and no (linear) activation for output layer\n",
        "\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "# construction\n",
        "input_linear_layer  = nn.Linear(2, 3) # linear tranformation (input 2, output=1)\n",
        "relu_activation  = nn.ReLU()\n",
        "output_linear_layer = nn.Linear(3, 1) # linear transformation module (input=3, output=1)\n"
      ],
      "metadata": {
        "id": "7ifJXL9nuzd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the Linear layers now**"
      ],
      "metadata": {
        "id": "qXjuRBT6vdR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 2 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2)\n",
        "number_of_samples = 1\n",
        "random_X = torch.randn(number_of_samples, 2) # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvrVZVoavhvL",
        "outputId": "d4224052-6f4f-478c-ac66-927f23c24359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply forward pass through the network\n",
        "hidden_layer_output = input_linear_layer(random_X)\n",
        "hidden_layer_output_relu = relu_activation(hidden_layer_output)\n",
        "output = output_linear_layer(hidden_layer_output_relu)\n",
        "print('Output layer result: ', output.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6nw27mN81f2",
        "outputId": "f7c4d202-1694-448c-abfb-f0fa8ce67b1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output layer result:  tensor([[-0.1279]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducing ... nn.Sequential"
      ],
      "metadata": {
        "id": "2azscuX8wHjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of our network\n",
        "torch.manual_seed(2)\n",
        "my_first_mlp = nn.Sequential(\n",
        "                nn.Linear(2, 3),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(3, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "ofXYbvCcs55M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass step\n",
        "torch.manual_seed(2)\n",
        "rand_input = random_X\n",
        "output = my_first_mlp(rand_input)\n",
        "print('final output: ', output.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq-ikA7Qw_R0",
        "outputId": "fe40d772-0f31-4df1-d66e-8be75afec9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final output:  tensor([[-0.1279]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exercise#5**\n",
        "Create three Linear layers and connect them in sequence to build an MLP with the following structure:\n",
        "\n",
        "> The first layer has 2 input nodes and 3 output nodes.\n",
        "\n",
        "> The second layer takes 3 input nodes and outputs 6 nodes.\n",
        "\n",
        "> The final layer connects 6 input nodes to 1 output node.\n",
        "\n",
        "> The activation functions should be Sigmoid for each layer (including the final layer)\n",
        "\n",
        "> Put all of your code in a single CoLab cell. Start the code with `torch.manual_seed(2)`\n",
        "\n",
        "> Execute a forward pass step with the initial values; `input_x = torch.tensor( [[-0.5,0.5]] )`"
      ],
      "metadata": {
        "id": "-hkSrqXu1Q25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)\n",
        "my_first_mlp = nn.Sequential(\n",
        "                nn.Linear(2, 3),\n",
        "                nn.Sigmoid(),\n",
        "                nn.Linear(3, 6),\n",
        "                nn.Sigmoid(),\n",
        "                nn.Linear(6, 1),\n",
        "                nn.Sigmoid()\n",
        ")\n",
        "\n",
        "input_x = torch.tensor( [[-0.5,0.5]] )\n",
        "output = my_first_mlp(input_x)\n",
        "print('final output: ', output.data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du2QLolc16IP",
        "outputId": "a526c8fe-59b8-4db2-9c64-d9ffe34f00ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final output:  tensor([[0.4365]])\n"
          ]
        }
      ]
    }
  ]
}