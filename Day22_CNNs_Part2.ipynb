{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNaDzVW1sWd+usjgKA6KGhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day22_CNNs_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day22\n",
        "## Intro to Convolutional Neural Networks (CNNs) Part 2\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Put the Model on Training Device (GPU or CPU)__\n",
        "\n",
        "\n",
        "We want to accelerate the training process using graphical processing unit (GPU). Fortunately, in Colab we can access for GPU. You need to enable it from _Runtime (or click on the down arrow near RAM & DISK in upper right)-->Change runtime type-->GPU or TPU_\n",
        "\n",
        "Professor Urness tested this code with the GPU option: T4"
      ],
      "metadata": {
        "id": "3awNnb-YtDpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "# if it prints 'cuda' then colab is running using GPU device"
      ],
      "metadata": {
        "id": "7KRrGdHZtKK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "seed = 41  # you can choose any integer\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# If using CUDA:\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)  # if using multi-GPU"
      ],
      "metadata": {
        "id": "33CGz1E9H4Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PjU46rJrpQZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Load the Dataset for your CNN__"
      ],
      "metadata": {
        "id": "yaX9rSh0j3vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily import some [built-in datasets](https://pytorch.org/vision/stable/datasets.html) from PyTorch's `torchvision.datasets` module\n",
        "- [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers/)\n",
        "  - each image size: 32x32 color images\n",
        "  - each image is associated with a label from __10 classes__ (0 through 9)\n",
        "  - 73257 digits for training, 26032 digits for testing"
      ],
      "metadata": {
        "id": "mkL47_1Aj7RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import SVHN\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "nd2uBJTNkyq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: ChatGPT\n",
        "# download the SVHN dataset -- this may take around 1 minute to download...\n",
        "transform = transforms.ToTensor()\n",
        "target_transform = lambda t: int(t) % 10  # maps label 10→0\n",
        "\n",
        "train_set = SVHN(root=\"/content/drive/MyDrive/CS167/datasets\", split=\"train\", download=True,\n",
        "                 transform=transform, target_transform=target_transform)\n",
        "test_set  = SVHN(root=\"/content/drive/MyDrive/CS167/datasets\", split=\"test\", download=True,\n",
        "                 transform=transform, target_transform=target_transform)"
      ],
      "metadata": {
        "id": "a3Riha7HkNQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explore some sample training images__"
      ],
      "metadata": {
        "id": "-KQ-wrtPJ6NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: ChatGPT\n",
        "\n",
        "# load up a batch of 32 train images\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# Helper to show a single tensor image\n",
        "def show_tensor_img(img_tensor, title=None):\n",
        "    # img_tensor is CxHxW in [0,1]\n",
        "    img = img_tensor.permute(1, 2, 0)  # -> HxWxC\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Show a few individual samples from the dataset\n",
        "for i in range(3):\n",
        "    img, label = train_set[i]\n",
        "    show_tensor_img(img, title=f\"Label: {label}\")\n",
        "\n",
        "# Show a small grid from a batch (with titles)\n",
        "batch_imgs, batch_labels = next(iter(train_loader))  # batch_imgs: [B,3,32,32]\n",
        "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
        "axes = axes.flatten()\n",
        "for ax, img, lbl in zip(axes, batch_imgs[:16], batch_labels[:16]):\n",
        "    ax.imshow(img.permute(1, 2, 0))\n",
        "    ax.set_title(f\"{int(lbl)}\")\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jeEOg0HTIkoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Building Convolutional Neural Network (CNN)__\n",
        "\n",
        "Create a network class with two methods:\n",
        "- _init()_\n",
        "- _forward()_"
      ],
      "metadata": {
        "id": "xv6DcogblNBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, we will follow this template for constructing other neural networks such as MLP in PyTorch. Here are the useful PyTorch modules we will be using for CNN construction:\n",
        "- [nn.Conv2d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "  - applies a 2D convolution over an input volume of $(C_{in}​,H_{in},W_{in})$ and produces an output volume of $(C_{out}​,H_{out},W_{out})$   between two adjacent layers.\n",
        "  - to create this, you need to provide the followings:\n",
        "    - __channel_dimension_of_input_layer__ i.e., $C_{in}$\n",
        "    - __channel_dimension_of_output_layer__ i.e., $C_{out}$\n",
        "    - __filter_size__ i.e., $F$\n",
        "\n",
        "  - the other two optional parameters are __stride__: $S=1$ and __padding__: $P=0$, with default values as shown.\n"
      ],
      "metadata": {
        "id": "fDC8pqIJlYJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__EXERCISE: You fill in Step #3__\n",
        "Refer to last Thursday's code. You will need to adjust the CNN to accomodate the color image and the 32x32 image dimensions."
      ],
      "metadata": {
        "id": "u04zn01kb8xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Putting Everything Together CNN__"
      ],
      "metadata": {
        "id": "b1i88s-Ltxzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "\n",
        "# import libraries\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import SVHN\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import time"
      ],
      "metadata": {
        "id": "FkCxgP_3uAIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: load the dataset (you did this above -- repeated here to put all of the steps in sequence)\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "target_transform = lambda t: int(t) % 10  # maps label 10→0\n",
        "\n",
        "train_set = SVHN(root=\"/content/drive/MyDrive/CS167/datasets\", split=\"train\", download=True,\n",
        "                 transform=transform, target_transform=target_transform)\n",
        "test_set  = SVHN(root=\"/content/drive/MyDrive/CS167/datasets\", split=\"test\", download=True,\n",
        "                 transform=transform, target_transform=target_transform)"
      ],
      "metadata": {
        "id": "kIeUZFDYuE6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "\n",
        "# Step 3: Create your CNN Network with 2 conv_2d layers + 2 layers of MLP\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "#### Your code here -- Look at last Thursday's code for inspiration\n",
        "####    you will have to update some numbers for different image sizes\n"
      ],
      "metadata": {
        "id": "RbcFlb01uQOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Your training and testing functions (updated -- now outputs accuracy to be visualized)\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    \"\"\"\n",
        "    Executes one full training epoch for the given model.\n",
        "\n",
        "    Iterates over all batches in the provided DataLoader, performing the following steps:\n",
        "    - Moves input and target tensors to the selected device (CPU or GPU)\n",
        "    - Computes predictions and loss for each batch\n",
        "    - Performs backpropagation and optimizer updates\n",
        "    - Tracks and prints training loss periodically\n",
        "\n",
        "    Args:\n",
        "        dataloader (torch.utils.data.DataLoader):\n",
        "            The DataLoader providing batches of training data (inputs and labels).\n",
        "        model (torch.nn.Module):\n",
        "            The neural network model to be trained.\n",
        "        loss_fn (torch.nn.Module or callable):\n",
        "            The loss function used to compute the training loss.\n",
        "        optimizer (torch.optim.Optimizer):\n",
        "            The optimizer responsible for updating the model’s parameters.\n",
        "\n",
        "    Returns:\n",
        "        float: The average training loss across all batches in this epoch.\n",
        "    \"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    model.train()                   # set the model to training mode for best practices\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    train_loss, correct = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # compute prediction and loss\n",
        "        X = X.to(device)                  # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()      # compute gradients\n",
        "        optimizer.step()     # apply updates\n",
        "        optimizer.zero_grad()# clear old gradients\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    correct /= size\n",
        "\n",
        "    return train_loss/len(dataloader), 100*correct\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    \"\"\"\n",
        "    Evaluates the model’s performance on a test (or validation) dataset.\n",
        "\n",
        "    Runs a forward pass over all batches in the provided DataLoader with gradient\n",
        "    computation disabled, accumulating loss and accuracy metrics.\n",
        "\n",
        "    Args:\n",
        "        dataloader (torch.utils.data.DataLoader):\n",
        "            The DataLoader providing batches of test or validation data.\n",
        "        model (torch.nn.Module):\n",
        "            The trained neural network model to evaluate.\n",
        "        loss_fn (torch.nn.Module or callable):\n",
        "            The loss function used to compute the evaluation loss.\n",
        "\n",
        "    Returns:\n",
        "        float: The average loss over all test batches.\n",
        "\n",
        "    Prints:\n",
        "        Accuracy (% of correct predictions) and average test loss.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()                    # set the model to evaluation mode for best practices\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "\n",
        "            X = X.to(device)                     # send data to the GPU device (if available)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, 100*correct\n"
      ],
      "metadata": {
        "id": "V4Equ7KOus7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: prepare the DataLoader and select your optimizer and set the parameters for learning the model from DataLoader\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "cnn_model = SimpleCNNv1() ## model Class name here\n",
        "cnn_model.to(device)      ## device should have been determined earlier (at top of notebook)\n",
        "learning_rate = 0.001\n",
        "batch_size_val = 64\n",
        "epochs = 10\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn_model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=batch_size_val)\n",
        "test_dataloader = DataLoader(test_set, batch_size=batch_size_val)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "test_losses  = []\n",
        "train_accuracy = []\n",
        "test_accuracy  = []\n",
        "start_time   = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    avg_train_loss, train_acc = train_loop(train_dataloader, cnn_model, loss_fn, optimizer)\n",
        "    avg_test_loss, test_acc  = test_loop(test_dataloader, cnn_model, loss_fn)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "print(\"Total execution time: %.3f sec\" %( (time.time()-start_time)) )\n",
        "print(\"Total execution time: %.3f hrs\" %( (time.time()-start_time)/3600) )\n",
        "\n",
        "print(cnn_model.__class__.__name__, \" model has been trained!\")\n"
      ],
      "metadata": {
        "id": "rHJfDg1puyHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Visualizing the accuracy curves\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "plt.plot(range(1,epochs+1), train_accuracy)\n",
        "plt.plot(range(1,epochs+1), test_accuracy)\n",
        "plt.title('Model accuracy after each epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Next5vqtu7Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__# Try other networks??__\n",
        "What about a kernel of 5?"
      ],
      "metadata": {
        "id": "2RDL1MpDeEPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "szv1PCh3sddg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Download the Dataset for AlexNet__"
      ],
      "metadata": {
        "id": "eNbCacx-ysah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __Bike-Cat-Dog-Person Dataset__\n",
        "  - Download `bcdp_v1.zip` via blackboard (under the dataset directory)\n",
        "    - Unzip the folder\n",
        "    - Upload the folder (bcdp_v1) to your Google Drive\n",
        "  - Each image size: __100x100x3__\n",
        "    - Note that these are color images\n",
        "  - Each image is associated with a label from __4 classes__\n",
        "  - Training set of __1500__ examples and test set of __300__ examples\n",
        "\n"
      ],
      "metadata": {
        "id": "ybfMiX5ZyqTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Prepare Your Data for Training__\n"
      ],
      "metadata": {
        "id": "wb_ZlRRwyvPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aKVzAbWM1VQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# For fine-tuning with an AlexNet/VGG/ResNet architecture that has been pre-trained using the ImageNet dataset, you need to normalize\n",
        "# each image with the given mean and standard deviation.\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),                     # Resize all images to 227x227 pixels (AlexNet input size)\n",
        "    transforms.ToTensor(),                             # Convert image to a PyTorch tensor and scale pixel values to [0, 1]\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),        # Subtract ImageNet mean for (R, G, B)\n",
        "                         (0.229, 0.224, 0.225))        # Divide by ImageNet std for (R, G, B)\n",
        "])\n",
        "train_dir       = '/content/drive/MyDrive/CS167/datasets/bcdp_v1/train'\n",
        "test_dir        = '/content/drive/MyDrive/CS167/datasets/bcdp_v1/test'\n",
        "\n",
        "train_dataset   = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset    = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "\n",
        "n_train         = len(train_dataset)\n",
        "n_test          = len(test_dataset)\n",
        "\n",
        "number_of_classes = 4\n",
        "\n",
        "print(\"Size of train set:\", n_train)\n",
        "print(\"Size of test set:\",  n_test)"
      ],
      "metadata": {
        "id": "B_iSaByxyzuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Building Convolutional Neural Network (CNN)__\n",
        "\n",
        "Create a network class with two methods:\n",
        "- _init()_\n",
        "- _forward()_\n"
      ],
      "metadata": {
        "id": "NnSjrDt31tex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "import pdb\n",
        "\n",
        "# You can give any name to your new network, e.g., AlexNet.\n",
        "# You should load the pretrained AlexNet model from torchvision.models.\n",
        "# This model was trained on over a million real-world images from ImageNet.\n",
        "# The idea is to bootstrap our CNN network weights with pretrained weights.\n",
        "# Our model will converge to a solution faster.\n",
        "# This training process is called 'fine-tuning.'\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(AlexNet, self).__init__()\n",
        "        net = models.alexnet(weights=AlexNet_Weights.DEFAULT)\n",
        "\n",
        "        # retain convolutional and pooling layers from the pretrained AlexNet\n",
        "        self.features = net.features\n",
        "        self.avgpool = net.avgpool\n",
        "\n",
        "        # replace the original classifier with a new one for custom output classes\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)         # extract convolutional feature maps\n",
        "        x = self.avgpool(x)          # reduce spatial dimensions to fixed 6x6\n",
        "        x = torch.flatten(x, 1)      # flatten to a 1D vector per image (batch stays intact)\n",
        "        x = self.classifier(x)       # apply fully connected layers for classification\n",
        "        return x                     # output class scores\n",
        "\n"
      ],
      "metadata": {
        "id": "TX98s4EE1vca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the structures of our cnn (based on AlexNet)\n",
        "\n",
        "cnn_model = AlexNet(number_of_classes)\n",
        "cnn_model.to(device)\n",
        "print(cnn_model)"
      ],
      "metadata": {
        "id": "GhowjOtA29ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Putting Everything Together for AlexNet__"
      ],
      "metadata": {
        "id": "8p6teJXk3G0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Putting Everything Together using our AlexNet Network on our 4-class image recognition Dataset__"
      ],
      "metadata": {
        "id": "J0c2Ovdj3KCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision import models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from torchvision.models import alexnet, AlexNet_Weights\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pdb\n",
        "\n",
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "gwGCka9a3n_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: load the dataset (as we did above)\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "# For fine-tuning with an AlexNet/VGG/ResNet architecture that has been pre-trained using the ImageNet dataset, you need to normalize\n",
        "# each image with the given mean and standard deviation.\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((227, 227)),                     # Resize all images to 227x227 pixels (AlexNet input size)\n",
        "    transforms.ToTensor(),                             # Convert image to a PyTorch tensor and scale pixel values to [0, 1]\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),        # Subtract ImageNet mean for (R, G, B)\n",
        "                         (0.229, 0.224, 0.225))        # Divide by ImageNet std for (R, G, B)\n",
        "])\n",
        "train_dir       = '/content/drive/MyDrive/CS167/datasets/bcdp_v1/train'\n",
        "test_dir        = '/content/drive/MyDrive/CS167/datasets/bcdp_v1/test'\n",
        "\n",
        "train_dataset   = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset    = datasets.ImageFolder(test_dir,  transform=transform)\n",
        "\n",
        "n_train         = len(train_dataset)\n",
        "n_test          = len(test_dataset)\n",
        "\n",
        "number_of_classes = 4\n",
        "\n",
        "print(\"Size of train set:\", n_train)\n",
        "print(\"Size of test set:\",  n_test)"
      ],
      "metadata": {
        "id": "FGjIEK723teY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Use the AlexNet from above\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "# You can give any name to your new network, e.g., AlexNet.\n",
        "# You should load the pretrained AlexNet model from torchvision.models.\n",
        "# This model was trained on over a million real-world images from ImageNet.\n",
        "# The idea is to bootstrap our CNN network weights with pretrained weights.\n",
        "# Our model will converge to a solution faster.\n",
        "# This training process is called 'fine-tuning.'\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(AlexNet, self).__init__()\n",
        "        net = alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # retain convolutional and pooling layers from the pretrained AlexNet\n",
        "        self.features = net.features\n",
        "        self.avgpool = net.avgpool\n",
        "\n",
        "        # replace the original classifier with a new one for custom output classes\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)         # extract convolutional feature maps\n",
        "        x = self.avgpool(x)          # reduce spatial dimensions to fixed 6x6\n",
        "        x = torch.flatten(x, 1)      # flatten to a 1D vector per image (batch stays intact)\n",
        "        x = self.classifier(x)       # apply fully connected layers for classification\n",
        "        return x                     # output class scores\n",
        "\n"
      ],
      "metadata": {
        "id": "mdB0jtCc31-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Your training and testing functions UPDATED TO OUTPUT TESTING CONFUSTION MATRIX\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "\n",
        "    size            = len(dataloader.dataset)\n",
        "    num_batches     = len(dataloader)\n",
        "\n",
        "    model.train()                   # set the model to training mode for best practices\n",
        "\n",
        "    train_loss      = 0\n",
        "    correct         = 0\n",
        "    train_pred_all  = []\n",
        "    train_y_all     = []\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # compute prediction and loss\n",
        "\n",
        "        # ----------- putting data into gpu or sticking to cpu ----------\n",
        "        X = X.to(device)     # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        # -----------                                         ----------\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "        # compute the accuracy\n",
        "        pred_prob   = softmax(pred)\n",
        "        pred_y \t\t\t= torch.max(pred_prob, 1)[1]\n",
        "        train_correct = (pred_y == y).sum()\n",
        "        correct    += train_correct.data\n",
        "\n",
        "        train_pred_all.append(pred_y) # save predicted output for the current batch\n",
        "        train_y_all.append(y)         # save ground truth for the current batch\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    train_pred_all = torch.cat(train_pred_all) # need to concatenate batch-wise appended items\n",
        "    train_y_all = torch.cat(train_y_all)\n",
        "\n",
        "    train_loss = train_loss/num_batches\n",
        "    correct    = correct.cpu().numpy()/size\n",
        "\n",
        "    print('Confusion matrix for training set:\\n', confusion_matrix(train_y_all.cpu().data, train_pred_all.cpu().data))\n",
        "    return train_loss, 100*correct\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "\n",
        "    model.eval()                    # set the model to evaluation mode for best practices\n",
        "\n",
        "    size                = len(dataloader.dataset)\n",
        "    num_batches         = len(dataloader)\n",
        "    test_loss, correct  = 0, 0\n",
        "    test_pred_all       = []\n",
        "    test_y_all          = []\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "\n",
        "      for X, y in dataloader:\n",
        "\n",
        "        # ----------- putting data into gpu or sticking to cpu ----------\n",
        "        X = X.to(device)     # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        # -----------                                         ----------\n",
        "\n",
        "        pred = model(X)\n",
        "        test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "        # calculate probability and save the outputs for confusion matrix computation\n",
        "        pred_prob     = softmax(pred)\n",
        "        pred_y        = torch.max(pred_prob, 1)[1]\n",
        "        test_correct  = (pred_y == y).sum()\n",
        "        correct      += test_correct.data\n",
        "\n",
        "        test_pred_all.append(pred_y) # save predicted output for the current batch\n",
        "        test_y_all.append(y)         # save ground truth for the current batch\n",
        "\n",
        "\n",
        "    #pdb.set_trace()\n",
        "    test_pred_all = torch.cat(test_pred_all)\n",
        "    test_y_all = torch.cat(test_y_all)\n",
        "\n",
        "    test_loss = test_loss/num_batches\n",
        "    correct   = correct.cpu().numpy()/size\n",
        "    print(f\"Test Performance: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print('Confusion matrix for test set:\\n', confusion_matrix(test_y_all.cpu().data, test_pred_all.cpu().data))\n",
        "    return test_loss, 100*correct, confusion_matrix(test_y_all.cpu().data, test_pred_all.cpu().data)\n"
      ],
      "metadata": {
        "id": "z_ydLufu3Yc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: prepare the DataLoader and select your optimizer and set the hyper-parameters for learning the model from DataLoader\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "cnn_model = AlexNet(number_of_classes)\n",
        "cnn_model.to(device)\n",
        "print(cnn_model)\n",
        "\n",
        "\n",
        "learning_rate     = 1e-4\n",
        "batch_size_val    = 32\n",
        "epochs            = 10\n",
        "loss_fn           = nn.CrossEntropyLoss()\n",
        "optimizer         = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
        "softmax           = nn.Softmax(dim=1) # for calculating the probability of the network prediction. It is used in train_loop() and test_loop().\n",
        "\n",
        "train_dataloader  = DataLoader(train_dataset, batch_size=batch_size_val, shuffle=True)  # shuffle the images in training set during fine-tuning\n",
        "test_dataloader   = DataLoader(test_dataset, batch_size=batch_size_val,  shuffle=False) # you don't need to shuffle test images as they are not used during training\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "test_losses  = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "start_time = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    avg_train_loss, train_accuracy                    = train_loop(train_dataloader, cnn_model, loss_fn, optimizer)\n",
        "    avg_test_loss, test_accuracy, conf_matrix_test    = test_loop(test_dataloader,   cnn_model, loss_fn)\n",
        "    # save the losses and accuracies\n",
        "    train_losses.append(avg_train_loss)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "print(\"AlexNet model has been fine-tuned!\")\n",
        "print(\"Total fine-tuning time: %.3f sec\" %( (time.time()-start_time)) )\n",
        "print(\"Total fine-tuning time: %.3f hrs\" %( (time.time()-start_time)/3600) )\n"
      ],
      "metadata": {
        "id": "Qx6CCAnG3dX0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the accuracy curves\n",
        "\n",
        "plt.plot(range(1,epochs+1), train_accuracies)\n",
        "plt.plot(range(1,epochs+1), test_accuracies)\n",
        "plt.title('Model accuracies after each epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jfM5bwX69bSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing the confusion matrix on the test set after the final epoch\n",
        "dataset_labels = ['bike', 'cat', 'dog', 'person'] # datasets.ImageFolder(): assigns labels according to the sorted order of the folder names\n",
        "\n",
        "# option #1: text\n",
        "print(pandas.DataFrame(conf_matrix_test, index = dataset_labels, columns = dataset_labels))\n",
        "\n",
        "# option #2: prettify\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_test, display_labels=dataset_labels)\n",
        "displ.plot(cmap=\"Blues\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WusjjGSy9m35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's demo our model --\n",
        "\n",
        "Credit: The following code was generated by ChatGPT"
      ],
      "metadata": {
        "id": "_Xu9EJ1H6IEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1) Get one random sample from the test set ---\n",
        "cnn_model.eval()\n",
        "idx = torch.randint(len(test_dataset), (1,)).item()\n",
        "img_tensor, y_true = test_dataset[idx]         # img_tensor is already transformed (resized + normalized)\n",
        "x = img_tensor.unsqueeze(0).to(device)         # shape [1, 3, 227, 227]\n",
        "\n",
        "# --- 2) Predict ---\n",
        "with torch.no_grad():\n",
        "    logits = cnn_model(x)\n",
        "    probs  = torch.softmax(logits, dim=1).squeeze(0).cpu()\n",
        "pred_idx = int(torch.argmax(probs))\n",
        "conf     = float(probs[pred_idx])\n",
        "\n",
        "# --- 3) Prepare image for display (un-normalize for viewing) ---\n",
        "# NOTE: This inverts *your* current Normalize(mean=(.229,.224,.225), std=(.485,.456,.406))\n",
        "# If you swap to the standard ImageNet stats (mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "# also update these to match.\n",
        "mean = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "std  = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "\n",
        "img_disp = img_tensor.cpu() * std + mean       # unnormalize\n",
        "img_disp = img_disp.clamp(0,1)                 # keep in [0,1]\n",
        "img_disp = img_disp.permute(1,2,0).numpy()     # CHW -> HWC\n",
        "\n",
        "# --- 4) Labels and thumbnail plot ---\n",
        "class_names = test_dataset.classes             # taken from ImageFolder folder names (sorted)\n",
        "pred_name   = class_names[pred_idx]\n",
        "true_name   = class_names[y_true]\n",
        "\n",
        "plt.figure(figsize=(2.4, 2.4))                 # \"thumbnail\"-sized\n",
        "plt.imshow(img_disp)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Pred: {pred_name} ({conf:.2f})\\nTrue: {true_name}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gkXafzLE6DzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__#Exercise__:\n",
        "\n",
        "Fine-tune a model with the bcdfh_v1.zip (bike, car, dog, flower, horse) dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "7xN1STV56kYb"
      }
    }
  ]
}