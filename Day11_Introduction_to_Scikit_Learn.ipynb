{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjSnb033epq1v0OyBlMQmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day11_Introduction_to_Scikit_Learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day11\n",
        "##Introduction to Scikit Learn\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4suW6U0oHxis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Review of Information Gain"
      ],
      "metadata": {
        "id": "WqMx1A9fHtmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def entropy(percentage_list):\n",
        "    #input: percentage_list consists of float values that sum to 1.0\n",
        "    #return: calculation of entropy for input percentages\n",
        "    result = 0\n",
        "    for percentage in percentage_list:\n",
        "        if percentage != 0:\n",
        "            result += -percentage*math.log2(percentage)\n",
        "    return result"
      ],
      "metadata": {
        "id": "5uFyglvzY4Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example #1"
      ],
      "metadata": {
        "id": "f5KK6yORIlY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Starting Entropy\n",
        "starting_entropy = entropy([7/13,6/13])\n",
        "starting_entropy"
      ],
      "metadata": {
        "id": "MlTSX7gpH8wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Expected Entropy\n",
        "expected_entropy = (7/13)*entropy([4/7,3/7]) + (6/13)*entropy([2/6,4/6])\n",
        "expected_entropy"
      ],
      "metadata": {
        "id": "gDz5paIQIGOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Information Gain\n",
        "information_gain = starting_entropy - expected_entropy\n",
        "information_gain"
      ],
      "metadata": {
        "id": "HHAAyV1GIJnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example #2\n",
        "You are given the following dataset where:\n",
        "- Day is the day of the week\n",
        "- Chicken Wrap is whether or not a chicken wrap was available\n",
        "- Hungry is whether you were hungry or not\n",
        "- Choice is the choice you made as to where to eat\n",
        "\n",
        "### What is the information gain of the `Hungry` column?\n",
        "\n",
        "| **Day**   | **Chicken Wrap** | **Hungry** | **Choice** |\n",
        "|-----------|------------------|------------|------------|\n",
        "| Monday    | yes              | no         | Hubbell    |\n",
        "| Wednesday | no               | yes        | Starbucks  |\n",
        "| Monday    | yes              | yes        | Hubbell    |\n",
        "| Wednesday | no               | no         | Hubbell    |\n",
        "| Monday    | no               | yes        | Starbucks  |"
      ],
      "metadata": {
        "id": "miQjq3l_Inex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Starting Entropy\n",
        "starting_entropy = entropy([3/5,2/5])\n",
        "starting_entropy"
      ],
      "metadata": {
        "id": "Dm3YrNBEIs9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Expected Entropy\n",
        "expected_entropy = (3/5)*entropy([1/3,2/3]) + (2/5)*entropy([2/2,0/2])\n",
        "expected_entropy"
      ],
      "metadata": {
        "id": "EfJPpp-UI0RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Information Gain\n",
        "information_gain = starting_entropy - expected_entropy\n",
        "information_gain"
      ],
      "metadata": {
        "id": "INxbIrjZJGBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mk0Iry5AJOJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Scikit Learn"
      ],
      "metadata": {
        "id": "og2SbJiHJge4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Scikit Learn 'Algorithm':\n",
        "\n",
        "When working in Scikit Learn (`sklearn`), there is a general pattern that we can follow to implement any supported machine learning algorithm.\n",
        "\n",
        "It goes like this:\n",
        "1. Load your data using `pd.read_csv()`\n",
        "2. Split your data `train_test_split()`\n",
        "3. Create your classifier/regressor object\n",
        "4. Call `fit()` to train your model\n",
        "5. Call `predict()` to get predictions\n",
        "6. Call a metric function to measure the performance of your model."
      ],
      "metadata": {
        "id": "EUznYUEXS90v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "00UWYEjFTVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classic scikit-learn algorithm\n",
        "\n",
        "#0. import libraries\n",
        "import sklearn\n",
        "import pandas\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import neighbors\n",
        "\n",
        "#1. load data\n",
        "iris_df = pandas.read_csv(\"/content/drive/MyDrive/CS167/datasets/irisData.csv\")\n",
        "\n",
        "#2. split data\n",
        "predictors = ['sepal length', 'sepal width','petal length', 'petal width']\n",
        "target = \"species\"\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "        train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "#3. Create classifier/regressor object (change these parameters for In-Class Exercise)\n",
        "dt = tree.DecisionTreeClassifier(random_state=41)\n",
        "\n",
        "#4. Call fit (to train the classification/regression model)\n",
        "dt.fit(train_data,train_sln)\n",
        "\n",
        "#5. Call predict to generate predictions\n",
        "iris_predictions = dt.predict(test_data)\n",
        "\n",
        "#6. Call a metric function to measure performance\n",
        "print(\"Accuracy:\", metrics.accuracy_score(test_sln,iris_predictions))\n",
        "\n",
        "# Show the acutal and predicted (this isn't necessary, but may help catch bugs)\n",
        "print(\"___PREDICTED___ \\t  ___ACTUAL___\")\n",
        "for i in range(len(test_sln)):\n",
        "    print(iris_predictions[i],\"\\t\\t\", test_sln.iloc[i])\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "#print out a confusion matrix\n",
        "iris_labels= [\"Iris-setosa\", \"Iris-versicolor\",\"Iris-virginica\"]\n",
        "conf_mat = metrics.confusion_matrix(test_sln, iris_predictions, labels=iris_labels)\n",
        "print(pandas.DataFrame(conf_mat,index = iris_labels, columns = iris_labels))"
      ],
      "metadata": {
        "id": "nas9BvJ1TZBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, let's go through step-by-step:"
      ],
      "metadata": {
        "id": "BjDdtmK64nVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import libraries and load your data\n",
        "\n",
        "We should be pretty familiar with this one.\n",
        "- mount your drive\n",
        "- import any relevant libraires\n",
        "- use `pd.read_csv()` to load in your dataset"
      ],
      "metadata": {
        "id": "1jd1nrTS4mB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JwXkgNnd4sEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0. import libraries\n",
        "import sklearn\n",
        "import pandas\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import neighbors\n",
        "\n",
        "#1. load data\n",
        "path = '/content/drive/MyDrive/CS167/datasets/irisData.csv'\n",
        "iris_df = pandas.read_csv(path)"
      ],
      "metadata": {
        "id": "GkP5VgV24tvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Split Data\n",
        "\n",
        "Cross-Validation is an important step in machine learning which enables us to evaluate our models. To do this, we need to split our data into `train_data` and `test_data`.\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/day04_cross_validation.png\" width=600/>\n",
        "</div>"
      ],
      "metadata": {
        "id": "6o4mKEbA4zWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit Learn takes this a step further and splits the data up into 4 pieces:\n",
        "\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/day06_traintestsplit.png\" width=600/>\n",
        "</div>\n",
        "\n",
        "- `train_data`: holds the predictor variables of the training set\n",
        "- `train_sln`: holds the target variable of the training set\n",
        "- `test_data`: holds the predictor variables of the testing set\n",
        "- `test_sln`: holds the target varibles of the testing set"
      ],
      "metadata": {
        "id": "ai85fgzQ9lZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2. split data\n",
        "predictors = ['sepal length', 'sepal width','petal length', 'petal width']\n",
        "#predictors = iris_df.columns.drop('species')\n",
        "target = \"species\"\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)"
      ],
      "metadata": {
        "id": "lPaypd6w-01t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a look at the data... make sure you understand what split of data is stored in each\n",
        "print('train_data shape: ',train_data.shape)\n",
        "print('test_data shape: ',test_data.shape)\n",
        "print('train_sln shape: ',train_sln.shape)\n",
        "print('test_sln shape: ',test_sln.shape)\n",
        "\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "F1f2AXND_SLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Create classifier/regressor object\n",
        "\n",
        "The syntax/wording for this is going to come directly from the `sklearn` documentation.\n",
        "- [Scikit Learn Decision Tree documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
        "\n",
        "The name of the model will change based on whether you are doing a __classification__ or __regression__.\n",
        "- generally in the name:\n",
        "    - `tree.DecicionTreeClassifier()`\n",
        "    - `tree.DecisionTreeRegressor()`"
      ],
      "metadata": {
        "id": "NuQSM80uCJhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Create classifier/regressor object (change these parameters for In-Class Exercise #1)\n",
        "dt = tree.DecisionTreeClassifier(random_state=2)"
      ],
      "metadata": {
        "id": "SNFa_TL6BSYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Call `fit()` to train the model\n",
        "\n",
        "Each machine learning model has a training process associated with it. Scikit learn makes it easy to train whatever model you choose by simply calling `fit()` on that model.\n",
        "\n",
        "We generally pass two things into `fit()`:\n",
        "- `train_data`: the predictor variables we want to train our model on\n",
        "- `train_sln`: the labels for each training examples\n"
      ],
      "metadata": {
        "id": "LPkzTRQhCN5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Call fit (to train the classification/regression model)\n",
        "dt.fit(train_data, train_sln)"
      ],
      "metadata": {
        "id": "DWDqNMJyDXpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Call `predict()` to get predictions\n",
        "\n",
        "After our model is trained, it's time to run our testing data through our model and see what the model predicts.\n",
        "\n",
        "Scikit learn lets us do this in one line:\n",
        "- we're saving what the function is returning as `predictions`\n",
        "- passing in `test_data`, which is the data without labels that was not included in training\\"
      ],
      "metadata": {
        "id": "umnBenjgEvMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Call predict to generate predictions\n",
        "predictions = dt.predict(test_data)"
      ],
      "metadata": {
        "id": "CCmwDOBXEubA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Evaluate the Model\n",
        "\n",
        "Now that we have some predictions, we need to check to see how close we were by passing our predictions and the actual correct answers into a metric function.\n",
        "\n",
        "| **Type of ML** | **Metric**                | **Description**                                                                                       | Scikit Learn                                                                                                                                                            |\n",
        "|----------------|---------------------------|:-------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Classification | Accuracy                  | Number correct examples divided by total number                                                       | [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)                                               |\n",
        "| Classification | Confusion Matrix          | Detailed table of where our model got confused.                                                       | [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix)          |\n",
        "| Regression     | Mean Absolute Error (MAE) | The average absolute distance from the target variable                                                | [`sklearn.metrics.mean_absolute_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error) |\n",
        "| Regression     | Mean Squared Error (MSE)  | The average squared distance from the target variable                                                 | [`sklearn.metrics.mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error)    |\n",
        "| Regression     | $R^2$                     | 1: perfectly fit data 0: same performance as guessing the mean of the target variable| [`sklearn.metrics.r2_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score)                                  |\n",
        "\n",
        "Available metrics can be found in the sklearn documentation [[sklearn metrics]](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
      ],
      "metadata": {
        "id": "_d6Yd9B6IGZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "#6. call a metric function to evaluate the model\n",
        "print(\"Accuracy:\", metrics.accuracy_score(test_sln, predictions))"
      ],
      "metadata": {
        "id": "eXq8Q3v1IYRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of displaying a confusion matrix:\n",
        "Documentation link: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "LjpN0kNSIqla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "#print out a confusion matrix\n",
        "iris_labels= [\"Iris-setosa\", \"Iris-versicolor\",\"Iris-virginica\"]\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=iris_labels)\n",
        "print(pandas.DataFrame(conf_mat,index = iris_labels, columns = iris_labels))"
      ],
      "metadata": {
        "id": "jQ8TKp9IIzfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Option #2\n",
        "displ = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=iris_labels)\n",
        "displ.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C1Wkn6YtJDXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Step 7: Print out the results to debug\n",
        "\n",
        "Sometimes its helpful to take a closer look at your predictions. Here's some code to do just that:"
      ],
      "metadata": {
        "id": "f4XwXzWiJ5gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the acutal and predicted (this isn't necessary, but may help catch bugs)\n",
        "print(\"___PREDICTED___ \\t  ___ACTUAL___\")\n",
        "for i in range(len(test_sln)):\n",
        "    print(predictions[i],\"\\t\\t\", test_sln.iloc[i])"
      ],
      "metadata": {
        "id": "U0pbA8-jBNm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Class Exercise #1:\n",
        "\n",
        "\n",
        "Take a look at the [Decision Tree Classifier Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html):\n",
        "- Explore different parameters you could use in the `DecisionTreeClassifier`\n",
        "  - *hint: in Step #3, consider different values for `max_depth`*\n",
        "- Can you improve accuracy to something **greater than 85%** without touching the  `random_state` parameters?\n",
        "  - Use\n",
        "  - `train_data, test_data, train_sln, test_sln =\n",
        "        train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)` and\n",
        "  - `dt = tree.DecisionTreeClassifier(random_state=2)`\n",
        "- How did you accomplish this?"
      ],
      "metadata": {
        "id": "YnvoHh9uBeGA"
      }
    }
  ]
}