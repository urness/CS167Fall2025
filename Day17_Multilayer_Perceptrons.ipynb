{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0ePfP54phds2h+W3JgzUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day17_Multilayer_Perceptrons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day17\n",
        "## Multilayer Perceptrons\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "00UWYEjFTVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ],
      "metadata": {
        "id": "j40BqYfzkxZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent"
      ],
      "metadata": {
        "id": "FQdveemHgquU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boston Housing Dataset:\n",
        "\n",
        "- CRIM - per capita crime rate by town\n",
        "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "- INDUS - proportion of non-retail business acres per town.\n",
        "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "- NOX - nitric oxides concentration (parts per 10 million)\n",
        "- RM - average number of rooms per dwelling\n",
        "- AGE - proportion of owner-occupied units built prior to 1940\n",
        "- DIS - weighted distances to five Boston employment centres\n",
        "- RAD - index of accessibility to radial highways\n",
        "- TAX - full-value property-tax rate per \\$10,000\n",
        "- PTRATIO - pupil-teacher ratio by town\n",
        "- LSTAT - % lower status of the population\n",
        "- MEDV - Median value of owner-occupied homes in \\$1000's"
      ],
      "metadata": {
        "id": "Qg00nuj3g1_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code using SGD on Boston Housing Dataset:\n",
        "\n",
        "# load the data\n",
        "housing_df = pd.read_csv(\"/content/drive/MyDrive/CS167/datasets/boston_housing.csv\")\n",
        "predictors = housing_df.columns.drop(\"MEDV\")\n",
        "target = \"MEDV\"\n",
        "\n",
        "#split the data\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "       train_test_split(housing_df[predictors], housing_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "#load up scikit-learn SGD\n",
        "sgd = SGDRegressor()\n",
        "sgd.fit(train_data,train_sln)\n",
        "predictions = sgd.predict(test_data)\n",
        "\n",
        "r2_value = r2_score(test_sln, predictions)\n",
        "print(\"SGD Regression R2 : \", r2_value)"
      ],
      "metadata": {
        "id": "hPesrAdcu4dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whoa. that's pretty bad. What's going on here?\n",
        "\n",
        "- [`sklearn` User Guide on Stochastic Gradient Descent](https://scikit-learn.org/stable/modules/sgd.html#)\n",
        "- Documentation: [`sklearn.linear_model.SGDRegressor()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)"
      ],
      "metadata": {
        "id": "bZEa_NQViOVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "HZMvPJvmPYlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptrons"
      ],
      "metadata": {
        "id": "zxGKFzTxpX2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load the data\n",
        "iris_df = pd.read_csv(\"/content/drive/MyDrive/CS167/datasets/irisData.csv\")\n",
        "\n",
        "#Split the dataset\n",
        "predictors = iris_df.columns.drop('species')\n",
        "target = \"species\"\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "#Normalize Data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_data)\n",
        "train_data_norm = scaler.transform(train_data)\n",
        "test_data_norm = scaler.transform(test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "17bwCknkDrMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a MLP using `sklearn`"
      ],
      "metadata": {
        "id": "yww3oPJLpkvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Class Exercise\n",
        "\n",
        "### In the code below, change the parameters to the call to `mlp = MLPClassifier()` (keeping `random_state=41`) to improve performance.\n",
        "\n",
        "- Describe the changes you made that ultimately helped improve performance.\n",
        "- Why do you think the changes you made helped?\n"
      ],
      "metadata": {
        "id": "pWxhGnVM5jjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #1 -- MLP Classifier"
      ],
      "metadata": {
        "id": "kXKw34RkugNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up MLP\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mlp = MLPClassifier(random_state=41,hidden_layer_sizes = (80,), max_iter = 20)\n",
        "mlp.fit(train_data_norm,train_sln)\n",
        "predictions = mlp.predict(test_data_norm)\n",
        "\n",
        "print(\"Accuracy: \", metrics.accuracy_score(test_sln,predictions))\n",
        "\n",
        "# Confusion Matrix\n",
        "vals = iris_df[target].unique() ## possible classification values (species)\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,display_labels=mlp.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxIQuf9MppnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #2 -- MLP Regressor\n",
        "1. Read in the Boston Housing dataset\n",
        "2. Normalize your data\n",
        "3. Use a [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) to predict the price of a house 'MEDV'\n",
        "4. Play around with changing the parameters, see what the best R<sup>2</sup> score you can get is. Can you beat my high score of R<sup>2</sup>=0.6241535?"
      ],
      "metadata": {
        "id": "6MapyFIIufTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "# Code using SGD on Boston Housing Dataset:\n",
        "# load the data\n",
        "housing_df = pd.read_csv(\"/content/drive/MyDrive/CS167/datasets/boston_housing.csv\")\n",
        "predictors = housing_df.columns.drop(\"MEDV\")\n",
        "target = \"MEDV\"\n",
        "\n",
        "#split the data\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "       train_test_split(housing_df[predictors], housing_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "# Normalize the training data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() # creates new StandardScaler object\n",
        "scaler.fit(train_data) # compute the normalized values for predictors using training data\n",
        "train_data_normalized = scaler.transform(train_data) # apply normalization to training data predictors\n",
        "test_data_normalized = scaler.transform(test_data) # apply normalization to testing data predictors"
      ],
      "metadata": {
        "id": "2psajjzJue1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}