{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfB1f4nuEBc6BzPLuGtm4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day13_Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day13\n",
        "##Random Forests\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Warm up Exercise\n",
        "#### Download the breast-cancer-wisconsin-data.csv file from blackboard and upload it to your Google Drive\n",
        "\n",
        "  1. build a decision tree\n",
        "  2. what is the accuracy?\n",
        "  3. display a confusion matrix\n"
      ],
      "metadata": {
        "id": "L_svPSuXCxUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "00UWYEjFTVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0. import libraries\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "data= pd.read_csv(\"/content/drive/MyDrive/CS167/datasets/breast-cancer-data.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "Ep7V80K5JoQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split data\n",
        "target = \"diagnosis\"\n",
        "predictors = data.columns.drop(target) #gets all of the columns except the target\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(data[predictors], data[target], test_size = 0.2, random_state=41)"
      ],
      "metadata": {
        "id": "nas9BvJ1TZBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Warm up Exercise\n",
        "### Your code Here"
      ],
      "metadata": {
        "id": "83o1zqq3F0Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Code"
      ],
      "metadata": {
        "id": "AuBfXb2jFqpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In-Class Exercise #1:\n",
        "Look at [RandomForestClassifer Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
        "\n",
        "1.   What is the default number of trees?\n",
        "2.   Using `random_state = 0` as a parameter to `RandomForestClassifier`, How does increasing or decreasing the number of **trees** affect accuracy? (experiment by increasing/decreasing by 25 of the number of default trees)\n",
        "3.   What is the parameter to change to affect the number of features used?\n",
        "4.   Using `random_state = 0` as a parameter to `RandomForestClassifier`, and using the default number of trees, How does adjusting the number of **features** affect accuracy? Consider the possibilities of\n",
        "  - None\n",
        "  - 'sqrt'\n",
        "  - 'log2'\n",
        "  \n",
        "  \n",
        "  Which of the above (if any) will improve the accuracy?\n",
        "\n"
      ],
      "metadata": {
        "id": "7xztmoyYLAi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### a Random Forest Classifier\n",
        "\n",
        "# construct a random forest object (use random_state=0 as a parameter)\n",
        "\n",
        "# call .fit(train_data,train_sln)\n",
        "\n",
        "# generate predictions using the test_data\n",
        "\n",
        "# print out accuracy and confusion matrix\n",
        "print(\"accuracy score: \", metrics.accuracy_score(test_sln,predictions))\n",
        "\n",
        "vals = data[target].unique() ## possible classification values (M = malignant; B = benign)\n",
        "conf_mat = metrics.confusion_matrix(test_sln, predictions, labels=vals)\n",
        "print(pd.DataFrame(conf_mat, index = \"True \" + vals, columns = \"Predicted \" + vals))"
      ],
      "metadata": {
        "id": "fG_QyZRQVcrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importances"
      ],
      "metadata": {
        "id": "wdHG3wFPcFnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It looks like our random forest model achieved pretty good accuracy.\n",
        "# Now lets check how important each of the features was in the ensemble of models we built.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "#creates a list of numbers the right size to use as the index\n",
        "#and sorts the list so that the most important feature are first\n",
        "index = range(len(predictors))\n",
        "importances = forest.feature_importances_\n",
        "sorted_indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(8,10)) #making the table a bit bigger so the text is readable\n",
        "plt.title('Breast Cancer Feature Importances')\n",
        "plt.barh(range(len(sorted_indices)),importances[sorted_indices],height=0.8) #horizontal bar chart\n",
        "plt.ylabel('Feature')\n",
        "plt.yticks(index,predictors) #put the feature names at the y tick marks\n",
        "plt.xlabel(\"Random Forest Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNQ4fpIWcLol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning the Forest\n",
        "\n",
        "*   How can we tell how many trees to use?\n",
        "*   What about how many features to include in our trees?\n",
        "\n",
        "We can tune our random forest to find the best values of model\n",
        "parameters:\n",
        "\n"
      ],
      "metadata": {
        "id": "L1_-VF40c4eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This function just loops through a series of n_estimator values, builds a different model\n",
        "#for each, and then plots their respective accuracies. By making it a function, it's easier\n",
        "#to try out different ranges of numbers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def tune_number_of_trees(n_estimator_values):\n",
        "    rf_accuracies = []\n",
        "\n",
        "    for n in n_estimator_values:\n",
        "\n",
        "        curr_rf = RandomForestClassifier(n_estimators=n, random_state=0)\n",
        "        curr_rf.fit(train_data,train_sln)\n",
        "        curr_predictions = curr_rf.predict(test_data)\n",
        "        curr_accuracy = metrics.accuracy_score(test_sln,curr_predictions)\n",
        "        rf_accuracies.append(curr_accuracy)\n",
        "\n",
        "\n",
        "    plt.suptitle('Random Forest accuracy vs. number of trees',fontsize=18)\n",
        "    plt.xlabel('# trees')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.plot(n_estimator_values,rf_accuracies,'ro-')\n",
        "    plt.axis([0,n_estimator_values[-1]+1,.9,1])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "tune_number_of_trees(range(1,31))"
      ],
      "metadata": {
        "id": "NNDW9l7SdGAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like whether we are using small numbers of trees or large ones, the accuracy stays about the same. It appears at least sometimes that Random Forest doesn't take a lot of tuning of the number of trees."
      ],
      "metadata": {
        "id": "mYC81K4QdQ2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning Number of Features"
      ],
      "metadata": {
        "id": "EPqQHKXWd3jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_max_features(max_features_values):\n",
        "    rf_accuracies = []\n",
        "\n",
        "    for m in max_features_values:\n",
        "\n",
        "        curr_rf = RandomForestClassifier(n_estimators=10,max_features=m, random_state=0)\n",
        "        curr_rf.fit(train_data,train_sln)\n",
        "        curr_predictions = curr_rf.predict(test_data)\n",
        "        curr_accuracy = metrics.accuracy_score(test_sln,curr_predictions)\n",
        "        rf_accuracies.append(curr_accuracy)\n",
        "\n",
        "\n",
        "    plt.suptitle('Random Forest accuracy vs. max features',fontsize=18)\n",
        "    plt.xlabel('max features')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.plot(max_features_values,rf_accuracies,'ro-')\n",
        "    plt.axis([0,max_features_values[-1]+1,.9,1.01])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "tune_max_features(range(1,11))"
      ],
      "metadata": {
        "id": "zK0I25tUd2_a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}