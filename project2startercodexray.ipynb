{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13856771,"sourceType":"datasetVersion","datasetId":8827296},{"sourceId":13865759,"sourceType":"datasetVersion","datasetId":8834082}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Project #2\n## (your name here)\n\n#### CS167: Machine Learning, Fall 2025","metadata":{}},{"cell_type":"markdown","source":"## __Put the Model in GPU mode__\n\nWe want to accelerate the training process using graphical processing unit (GPU). You need to enable it (click Settings --> Accelerator--> GPU T4 x2)","metadata":{}},{"cell_type":"code","source":"import torch\n# check GPU (Kaggle will show \"cuda\" if GPU enabled in the notebook settings)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport random\n\n# Set seeds for reproducibility\nseed = 42  # you can choose any integer\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n# If using CUDA:\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)  # if using multi-GPU","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Step 1: imports (Kaggle version)\n# ============================================\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets, models\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport time\nimport os\n# ===========================================","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Step 2: Load the Data (Kaggle version)\n# ============================================\n\nbase_dir   = \"/kaggle/input/chest-xray\"      # <-- change this name to match your Kaggle dataset\ntrain_dir  = os.path.join(base_dir, \"chest_xray/train\")\ntest_dir   = os.path.join(base_dir, \"chest_xray/test\")\n\n# Use grayscale (since X-rays are single channel) and resize to AlexNet input\ntransform = transforms.Compose([\n    #transforms.Resize((227, 227)), ### AlexNet needs images that are 227x227\n    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))  # normalize single channel (mean,std)\n])\n\ntrain_dataset = datasets.ImageFolder(train_dir, transform=transform)\ntest_dataset  = datasets.ImageFolder(test_dir,  transform=transform)\n\ndataset_labels = train_dataset.classes\nnumber_of_classes = len(dataset_labels)\nprint(\"Classes:\", dataset_labels)\nprint(f\"Training samples: {len(train_dataset)}, Testing samples: {len(test_dataset)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Step 3: Create your MLP Network (with pooling)\n# ============================================\nimport torch\nfrom torch import nn\n\nclass SimpleMLPv2(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.network_layers = nn.Sequential(\n            # Input: (batch, 1, 200, 200)\n\n            nn.MaxPool2d(kernel_size=2),   # Output: (batch, 1, 100, 100)\n\n            nn.Flatten(),                   # Output: (batch, 10000)\n\n            nn.Linear(100 * 100, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.network_layers(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Step 4: training / testing loops \n# ============================================\ndef train_loop(dataloader, model, loss_fn, optimizer):\n    model.train()\n    size = len(dataloader.dataset)\n    running_loss = 0.0\n    correct = 0\n\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # forward + loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # backward + update\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        running_loss += loss.item()\n        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n    avg_loss = running_loss / len(dataloader)\n    accuracy = correct / size\n    return avg_loss, accuracy\n\ndef test_loop(dataloader, model, loss_fn):\n    model.eval()\n    size = len(dataloader.dataset)\n    running_loss = 0.0\n    correct = 0\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            loss = loss_fn(pred, y)\n\n            running_loss += loss.item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n\n            all_preds.append(pred.argmax(1).cpu())\n            all_labels.append(y.cpu())\n\n    avg_loss = running_loss / len(dataloader)\n    accuracy = correct / size\n\n    all_preds = torch.cat(all_preds)\n    all_labels = torch.cat(all_labels)\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n\n    return avg_loss, accuracy, conf_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# Step 5: Load the Data, Train the Model, Calculate the Results\n# ============================================\nmlp_model = SimpleMLPv2(number_of_classes)\nmlp_model.to(device)\nprint(mlp_model)\n\nlearning_rate   = 1e-4\nbatch_size_val  = 32\nepochs          = 10\nloss_fn         = nn.CrossEntropyLoss()\noptimizer       = optim.Adam(mlp_model.parameters(), lr=learning_rate)\nsoftmax         = nn.Softmax(dim=1)\n\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=batch_size_val,\n    shuffle=True,\n    num_workers=2,        # Kaggle: use workers to speed up loading\n    pin_memory=True if device == \"cuda\" else False\n)\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=batch_size_val,\n    shuffle=False,\n    num_workers=2,\n    pin_memory=True if device == \"cuda\" else False\n)\n\ntrain_losses = []\ntest_losses  = []\ntrain_accuracies = []\ntest_accuracies  = []\n\nstart_time = time.time()\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    avg_train_loss, train_accuracy = train_loop(train_dataloader, mlp_model, loss_fn, optimizer)\n    avg_test_loss, test_accuracy, conf_matrix_test = test_loop(test_dataloader, mlp_model, loss_fn)\n\n    train_losses.append(avg_train_loss)\n    test_losses.append(avg_test_loss)\n    train_accuracies.append(train_accuracy)\n    test_accuracies.append(test_accuracy)\n\n    print(f\"Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}\")\n    print(f\"Test  loss: {avg_test_loss:.4f}, Test  acc: {test_accuracy:.4f}\")\n\nprint(\"model has been fine-tuned!\")\ntotal_time_sec = time.time() - start_time\nprint(\"Total fine-tuning time: %.3f sec\" % total_time_sec)\nprint(\"Total fine-tuning time: %.3f hrs\" % (total_time_sec / 3600.0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualizing the accuracy curves\n\nplt.plot(range(1,epochs+1), train_accuracies)\nplt.plot(range(1,epochs+1), test_accuracies)\nplt.title('Model accuracies after each epoch')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'])\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show confusion matrix for final epoch\ndisp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_test, display_labels=dataset_labels)\ndisp.plot(xticks_rotation=45,cmap=\"Blues\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}