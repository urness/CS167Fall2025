{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzt/b8AdB1uqkQEXuDwpi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day08_Metrics_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day08\n",
        "##Metrics and Testing\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before we get started, let's load in our datasets:\n",
        "Make sure you change the path to match your Google Drive.\n"
      ],
      "metadata": {
        "id": "jiRjSmfA-9Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# The first step is to mount your Google Drive to your Colab account.\n",
        "#You will be asked to authorize Colab to access your Google Drive. Follow the steps they lead you.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nv96YoLBwemZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the data:\n",
        "#make sure the path on the line below corresponds to the path where you put your dataset.\n",
        "iris_df = pd.read_csv('/content/drive/MyDrive/CS167/datasets/irisData.csv')\n",
        "vehicles_df = pd.read_csv('/content/drive/MyDrive/CS167/datasets/vehicles.csv')"
      ],
      "metadata": {
        "id": "0wCCrNCE_6G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "2z9Fa7V-Kx50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graphs!"
      ],
      "metadata": {
        "id": "I3qLyRfwKrap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#define our data\n",
        "xvals = [1,2,3,4,5]\n",
        "series1 = [0.66,0.61,0.69,0.73,0.77]\n",
        "series2 = [0.8,0.83,0.77,0.81,0.79]\n",
        "series3 = [0.55,0.67,0.5,0.73,0.66]\n",
        "\n",
        "#add titles to axis and graph\n",
        "plt.suptitle('my rockin plot', fontsize=18)\n",
        "plt.xlabel('a very cool x axis')\n",
        "plt.ylabel('awesome y axis')\n",
        "\n",
        "#plot the data\n",
        "plt.plot(xvals, series1, 'ro--', label='1st series')\n",
        "plt.plot(xvals, series2, 'bs-.', label='2nd series')\n",
        "plt.plot(xvals, series3, 'g^-', label='3rd series')\n",
        "plt.axis([0,6,0,1]) #[x_min, x_max, y_min, y_max]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "86twf8O2K1YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gas_vehicles = vehicles_df[vehicles_df['fuelType']=='Regular']\n",
        "\n",
        "# a silly function that returns the average MPG for the first k cars in the df\n",
        "def getAverageMPG(data, k):\n",
        "    return data[\"comb08\"].iloc[0:k].mean()\n",
        "\n",
        "number_of_points = 500\n",
        "\n",
        "#populate the series list\n",
        "series = []\n",
        "for i in range(1, number_of_points):\n",
        "    val = getAverageMPG(gas_vehicles, i)\n",
        "    series.append(val)\n",
        "\n",
        "#plot it!\n",
        "xvals = range(1, number_of_points)\n",
        "plt.suptitle('Average MPG', fontsize=18)\n",
        "plt.xlabel('cars used in average')\n",
        "plt.ylabel('average MPG')\n",
        "plt.plot(xvals, series, 'r,-', label='MPG')\n",
        "plt.legend(loc='lower right', shadow=True)\n",
        "plt.axis([1, number_of_points, 10,25])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z7a4sqbDPODL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise here\n",
        "# change the number of points to 20\n",
        "# change the line to green triangles\n",
        "# also plot the median (red dots)\n"
      ],
      "metadata": {
        "id": "y2I8oxxIgSAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-Validation Code:\n",
        "\n",
        "A good rule of thumb is that we like to train our model with 80% of the training examples, and test it on 20% of the training examples.\n",
        "\n",
        "Splitting datasets into training and testing sets with a Pandas DataFrame:"
      ],
      "metadata": {
        "id": "3oTem3xigEsh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the data\n",
        "shuffled_data = iris_df.sample(frac=1, random_state=41)\n",
        "\n",
        "# Compute the split index (20% for test)\n",
        "test_size = int(0.2 * len(shuffled_data))\n",
        "\n",
        "# Set up training and testing sets\n",
        "test_data = shuffled_data.iloc[:test_size]     # first 20%\n",
        "train_data = shuffled_data.iloc[test_size:]    # remaining 80%\n",
        "\n",
        "train_data.shape"
      ],
      "metadata": {
        "id": "PQeGVNilgG9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "So55ugPqVrxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how accurate our kNN model is:\n"
      ],
      "metadata": {
        "id": "g4-aVes0WGSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's bring in our `kNN()` function--here I'm calling it `classify_kNN()` becuase it uses `mode()` to return the prediction which only works for classifcation."
      ],
      "metadata": {
        "id": "amY-BlnAWOXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_kNN(new_example,train_data,k):\n",
        "    #making a copy of the training set just so we don't mess up the original\n",
        "    train_data_copy = train_data.copy()\n",
        "\n",
        "    # 1. calculate distances\n",
        "    train_data_copy['distance_to_new'] = np.sqrt(\n",
        "     (new_example['petal length'] - train_data_copy['petal length'])**2\n",
        "    +(new_example['sepal length'] - train_data_copy['sepal length'])**2\n",
        "    +(new_example['petal width'] - train_data_copy['petal width'])**2\n",
        "    +(new_example['sepal width'] - train_data_copy['sepal width'])**2)\n",
        "\n",
        "    # 2. sort\n",
        "    sorted_data = train_data_copy.sort_values(['distance_to_new'])\n",
        "\n",
        "    # 3. predict\n",
        "    prediction = sorted_data.iloc[0:k]['species'].mode()[0]\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "9X_6MKzJdQ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's write a function `classify_all_kNN(test_data, train_data,k):` that:\n",
        "- goes through each example in the `test_data`, and gets the prediction using our `kNN()` function\n",
        "- It will return a pandas `Series` that has the predictions for each row in `test_data`.\n",
        "\n",
        "It should look something like this:"
      ],
      "metadata": {
        "id": "-sd7P86eYSGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_all_kNN(test_data, train_data, k) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Apply kNN classification to each row in the test data.\n",
        "\n",
        "    Parameters:\n",
        "        test_data (pd.DataFrame): Data to classify.\n",
        "        train_data (pd.DataFrame): Training set with labels.\n",
        "        k (int): Number of neighbors.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: Predicted labels for each row in test_data.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        prediction = classify_kNN(test_data.iloc[i], train_data, k)\n",
        "        results.append(prediction)\n",
        "\n",
        "    return pd.Series(results)"
      ],
      "metadata": {
        "id": "4kalCAL3Yv4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's pull it all together and see how our kNN does:"
      ],
      "metadata": {
        "id": "_ZLt1_XgY_Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predictions5NN = classify_all_kNN(test_data,train_data,5)\n",
        "\n",
        "#this will print out our predictions so we can see:\n",
        "print('ACTUAL            PREDICTIONS')\n",
        "for i in range(len(test_data)):\n",
        "    print(test_data['species'].iloc[i], \" \", predictions5NN.iloc[i] )\n",
        "\n",
        "acc = accuracy_score(test_data['species'], predictions5NN)\n",
        "print(\"accuracy:\", acc)"
      ],
      "metadata": {
        "id": "097Vo8vkZByl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's explore what the accuracy is for a variety of different values of k"
      ],
      "metadata": {
        "id": "KVZtB-enfN9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_vals = [1,3,5,9,15,21,31,51,101,119]\n",
        "kNN_accuracies = []\n",
        "\n",
        "for k in k_vals:\n",
        "    predictions = classify_all_kNN(test_data,train_data,k)\n",
        "    current_accuracy = accuracy_score(test_data['species'],predictions)\n",
        "    kNN_accuracies.append(current_accuracy)\n",
        "\n",
        "\n",
        "plt.suptitle('Iris Data k-NN Experiment',fontsize=18)\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('accuracy')\n",
        "plt.plot(k_vals,kNN_accuracies,'ro-',label='k-NN')\n",
        "plt.legend(loc='lower left', shadow=True)\n",
        "plt.axis([0,120,0,1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sisZKUPHfYdn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}