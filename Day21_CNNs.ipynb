{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6HjE97BwTObi1jFhSJL4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day21_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day21\n",
        "## Intro to Convolutional Neural Networks (CNNs)\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __Put the Model on Training Device (GPU or CPU)__\n",
        "\n",
        "\n",
        "We want to accelerate the training process using graphical processing unit (GPU). Fortunately, in Colab we can access for GPU. You need to enable it from _Runtime (or click on the down arrow near RAM & DISK in upper right)-->Change runtime type-->GPU or TPU_"
      ],
      "metadata": {
        "id": "3awNnb-YtDpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check to see if torch.cuda is available, otherwise it will use CPU\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "# if it prints 'cuda' then colab is running using GPU device"
      ],
      "metadata": {
        "id": "7KRrGdHZtKK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PjU46rJrpQZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Load the Dataset for your CNN__"
      ],
      "metadata": {
        "id": "yaX9rSh0j3vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily import some [built-in datasets](https://pytorch.org/vision/stable/datasets.html) from PyTorch's `torchvision.datasets` module\n",
        "- [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "  - each image size: 28x28 grayscale image\n",
        "  - each image is associated with a label from __10 classes__\n",
        "  - training set of 60,000 examples and a test set of 10,000 examples\n",
        "\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/fashion-mnist-sprite.png\" width=500/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "mkL47_1Aj7RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets # torchvision has many deep learning benchmark datasets Fashion-MNIST, CIFAR-10, Caltech-50, etc\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nd2uBJTNkyq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download FashionMNIST data\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"/content/drive/MyDrive/CS167/datasets\", # headsup! You can replace this path so that it points to a directory in your Google Drive\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor() # specify the feature and label transformations\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"/content/drive/MyDrive/CS167/datasets\", # headsup! You can replace this path so that it points to a directory in your Google Drive\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "a3Riha7HkNQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Explore some sample training images__"
      ],
      "metadata": {
        "id": "o-buNFkxkaDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a random set of images and their the labels from the training split\n",
        "# The following labels represent 10 classes, each with specific indices as defined by the creator of the Fashion-MNIST dataset\n",
        "# reference: https://github.com/zalandoresearch/fashion-mnist#labels\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(5, 5))\n",
        "cols, rows = 5, 2\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    #print('image tensor size:', img.shape)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\") # .squeeze() method removes the '1' from first dimension of the tensor [1, 28, 28]\n",
        "    #print('after removing the first dimension with ', img.squeeze().shape)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uOCKMDHkkr4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Prepare Your Data with DataLoader for Training/Testing__\n",
        "We just explored one sample of data at a time. As we have seen in our discussion of the optimizer, specifically __Stochastic Gradient Descent (SGD)__, during training your network, we may need to pass them in __minibatches__. PyTorch has a module called __DataLoader__, which will do this automatically for us as long as we provide the right arguments:\n",
        "- prepare the __minibatches__ with the given _batch_size_ eg 16, 32, 64, 128, etc\n",
        "- multiprocessing to speed up the data retrieval\n",
        "- reshuffle the data at every __epoch__\n"
      ],
      "metadata": {
        "id": "wH6aYv0NlAM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "#                              pairs of items,   minibatch size,        random shuffling turned ON\n",
        "train_dataloader = DataLoader(training_data,     batch_size=128,        shuffle=True)\n",
        "test_dataloader  = DataLoader(test_data,         batch_size=128,        shuffle=False) # for testing/inference: it is not necessary to shuffle"
      ],
      "metadata": {
        "id": "SoayH2L3lGt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# explore the data from the train_dataloader\n",
        "train_inputs, train_labels = next(iter(train_dataloader)) # returns a batch of 128 train-images and train-labels\n",
        "print(f\"Images batch shape: {train_inputs.shape}\")\n",
        "print(f\"Labels batch shape: {train_labels.shape}\")\n",
        "\n",
        "# visualize one of the samples in this batch of 128\n",
        "figure = plt.figure(figsize=(2, 2))\n",
        "img = train_inputs[127].squeeze() # I picked 127 but you can pick any index in between 0 to batch_size=128\n",
        "label = train_labels[127]         # It's a tensor datatype\n",
        "plt.title(labels_map[int(label)]) # For indexing, convert the 'tensor' datatype --> integer number datatype\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "ipGwu0GhlE3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Building Convolutional Neural Network (CNN)__\n",
        "\n",
        "Create a network class with two methods:\n",
        "- _init()_\n",
        "- _forward()_"
      ],
      "metadata": {
        "id": "xv6DcogblNBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, we will follow this template for constructing other neural networks such as MLP in PyTorch. Here are the useful PyTorch modules we will be using for CNN construction:\n",
        "- [nn.Conv2d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "  - applies a 2D convolution over an input volume of $(C_{in}​,H_{in},W_{in})$ and produces an output volume of $(C_{out}​,H_{out},W_{out})$   between two adjacent layers.\n",
        "  - to create this, you need to provide the followings:\n",
        "    - __channel_dimension_of_input_layer__ i.e., $C_{in}$\n",
        "    - __channel_dimension_of_output_layer__ i.e., $C_{out}$\n",
        "    - __filter_size__ i.e., $F$\n",
        "\n",
        "  - the other two optional parameters are __stride__: $S=1$ and __padding__: $P=0$, with default values as shown.\n"
      ],
      "metadata": {
        "id": "fDC8pqIJlYJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class SimpleCNNv1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "\n",
        "    # note input image is greyscale and has dimension of [1,28,28]\n",
        "\n",
        "    # Beginning layers: a series of 2D convolutional layers (useful for feature map learning from the grid layouts of an image)\n",
        "    self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3),   # -> maps input grey scale image (1 channel) to a conv layer of 32 channels; output dimension of [32,26,26]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3),  # -> input of 32 channels to conv. layer of 64 channels; output dimensions of [64,24,24]\n",
        "            nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # -------                 heads up!                                 --------\n",
        "    # you need to calculate the total_size_of_the_output_volume of your self.second_conv_2d layer,\n",
        "    # as it will be needed by the upcoming nn.Linear(). This number will be used as the first argument for the next nn.Linear().\n",
        "    # I pre-calculated this number, and it is 64*24*24 = 36864. I will plug this number in the next layer\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    self.flatten = nn.Flatten() # -> flatten the tensor to prepare for a fully connected MLP layer; resulting layer is [64*24*24]\n",
        "\n",
        "    self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(64*24*24, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)     # 10 is the number of classes in the classification task\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # your code for Conv_2d forward pass should take place here\n",
        "    output = self.conv_layers(x)\n",
        "    output = self.flatten(output)\n",
        "    output = self.linear_layers(output)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "HE8rXrcymhFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the structure of your CNN\n",
        "cnn_model = SimpleCNNv1()\n",
        "print(cnn_model)"
      ],
      "metadata": {
        "id": "y5ukIWShpmef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Forward Pass using your Dataset and your CNN__\n",
        "Test a forward pass of our first CNN using one of the training samples.\n",
        "The forward method inside our network class, __SimpleCNNv1__, will be invoked if we provide an input tensor __X__ to the network object we instantiated earlier, i.e., __cnn_model__, as follows:\n",
        "- _output = cnn_model(X)_\n",
        "\n",
        "Finally, we convert the ouput from the model into probabilities using __Softmax()__ module:\n",
        "- _pred_probab = softmax_activation(output)_"
      ],
      "metadata": {
        "id": "07qcVf8Lq42U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img   = train_inputs[100] # I picked 100 but you can pick any index in between 0 to batch_size-1=127\n",
        "label = train_labels[100]\n",
        "\n",
        "softmax_activation = nn.Softmax(dim=1)\n",
        "\n",
        "# Load up the model\n",
        "mlp_model = SimpleCNNv1()\n",
        "mlp_model.eval\n",
        "\n",
        "# data and model should be placed to the same device (either GPU or CPU)\n",
        "X = img.unsqueeze(0).to(device)         # sending the data tensor to GPU (if available)\n",
        "mlp_model.to(device)                      # sending the model to GPU (if available) print(f\"device {device} and model: \\n {mlp_model}\")\n",
        "output = mlp_model(X)\n",
        "\n",
        "predicted_probability = softmax_activation(output)  # these raw numbers scaled to values [0, 1] representing the model’s predicted probabilities for each class\n",
        "\n",
        "print('predited probability \\n', predicted_probability)\n",
        "y_pred = predicted_probability.argmax()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Actual class: {label}\")\n"
      ],
      "metadata": {
        "id": "lEyU243Wq-RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Defining Loss function__\n",
        "\n",
        "- [nn.CrossEntropyLoss()](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)\n",
        "  - useful when training a __classification problem__ with __C__ classes.\n",
        "  - criterion computes the cross entropy loss between input logits (raw scores before softmax) and target\n",
        "- [nn.MSELoss()](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
        "  - useful when training a __regression problem__\n",
        "  - criterion that measures the mean squared error (squared L2 norm) between each element in the input _x_ and target _y_\n"
      ],
      "metadata": {
        "id": "TUd6bgXutaOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss() # this is useful for multiclass classification task"
      ],
      "metadata": {
        "id": "Ltctev04tgUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##__Initializing the Optimizer__\n",
        "\n",
        "Optimiztaion, as we have discussed earlier, is process of adjusting model parameters to reduce model error in each training step.\n",
        "\n",
        "PyTorch provides a selection of optimization algorithms in the [torch.optim](https://pytorch.org/docs/stable/optim.html) package. Some of them are as follows:\n",
        "- [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)\n",
        "- [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- [torch.optim.RMSprop](https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html#torch.optim.RMSprop)\n",
        "\n",
        "In addition to selecting the optimizer, we can also select the hyperparameters which are referred to as *adjustable parameters* crucial for controlling the model optimization process. You can influence the training and convergence of the model by tweaking these hyperparameters:\n",
        "- __epochs:__ denotes the number of iterations over the dataset\n",
        "- __batch size:__ represents the quantity of data samples in each iteration propagated through the network before updating the parameters\n",
        "- __learning rate:__ determines the extent of parameter updates made at each batch/epoch\n",
        "\n"
      ],
      "metadata": {
        "id": "4WTvzfwXtlMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size    = 64\n",
        "epochs        = 10\n",
        "# let's use SGD optimization algorithm for training our model\n",
        "optimizer     = torch.optim.SGD(cnn_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Q5iQ2B0Btkem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#__Putting Everything Together CNN__"
      ],
      "metadata": {
        "id": "b1i88s-Ltxzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: load the Torch library and other utilities\n",
        "#----------------------------------------------------\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import time"
      ],
      "metadata": {
        "id": "FkCxgP_3uAIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: load the dataset, ie, we are experimenting with FashionMNIST\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"/content/drive/MyDrive/CS167/datasets\", # headsup! You can replace this path so that it points to a directory in your Google Drive\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor() # specify the feature and label transformations\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"/content/drive/MyDrive/CS167/datasets\", # headsup! You can replace this path so that it points to a directory in your Google Drive\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "kIeUZFDYuE6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create your CNN Network (call it SimpleCNNv2) with 2 conv_2d layers + 2 layers of MLP\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "\n",
        "class SimpleCNNv1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # your network layer construction should take place here\n",
        "\n",
        "    # note input image is greyscale and has dimension of [1,28,28]\n",
        "\n",
        "    # Beginning layers: a series of 2D convolutional layers (useful for feature map learning from the grid layouts of an image)\n",
        "    self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3),   # -> maps input grey scale image (1 channel) to a conv layer of 32 channels; output dimension of [32,26,26]\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3),  # -> input of 32 channels to conv. layer of 64 channels; output dimensions of [64,24,24]\n",
        "            nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # -------                 heads up!                                 --------\n",
        "    # you need to calculate the total_size_of_the_output_volume of your self.second_conv_2d layer,\n",
        "    # as it will be needed by the upcoming nn.Linear(). This number will be used as the first argument for the next nn.Linear().\n",
        "    # I pre-calculated this number, and it is 64*24*24 = 36864. I will plug this number in the next layer\n",
        "    # --------------------------------------------------------------------------\n",
        "\n",
        "    self.flatten = nn.Flatten() # -> flatten the tensor to prepare for a fully connected MLP layer; resulting layer is [64*24*24]\n",
        "\n",
        "    self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(64*24*24, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)     # 10 is the number of classes in the classification task\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # your code for Conv_2d forward pass should take place here\n",
        "    output = self.conv_layers(x)\n",
        "    output = self.flatten(output)\n",
        "    output = self.linear_layers(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "RbcFlb01uQOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Your training and testing functions (updated -- now outputs accuracy to be visualized)\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    \"\"\"\n",
        "    Executes one full training epoch for the given model.\n",
        "\n",
        "    Iterates over all batches in the provided DataLoader, performing the following steps:\n",
        "    - Moves input and target tensors to the selected device (CPU or GPU)\n",
        "    - Computes predictions and loss for each batch\n",
        "    - Performs backpropagation and optimizer updates\n",
        "    - Tracks and prints training loss periodically\n",
        "\n",
        "    Args:\n",
        "        dataloader (torch.utils.data.DataLoader):\n",
        "            The DataLoader providing batches of training data (inputs and labels).\n",
        "        model (torch.nn.Module):\n",
        "            The neural network model to be trained.\n",
        "        loss_fn (torch.nn.Module or callable):\n",
        "            The loss function used to compute the training loss.\n",
        "        optimizer (torch.optim.Optimizer):\n",
        "            The optimizer responsible for updating the model’s parameters.\n",
        "\n",
        "    Returns:\n",
        "        float: The average training loss across all batches in this epoch.\n",
        "    \"\"\"\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    model.train()                   # set the model to training mode for best practices\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    train_loss, correct = 0, 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "\n",
        "        # compute prediction and loss\n",
        "        X = X.to(device)                  # send data to the GPU device (if available)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()      # compute gradients\n",
        "        optimizer.step()     # apply updates\n",
        "        optimizer.zero_grad()# clear old gradients\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    correct /= size\n",
        "\n",
        "    return train_loss/len(dataloader), 100*correct\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    \"\"\"\n",
        "    Evaluates the model’s performance on a test (or validation) dataset.\n",
        "\n",
        "    Runs a forward pass over all batches in the provided DataLoader with gradient\n",
        "    computation disabled, accumulating loss and accuracy metrics.\n",
        "\n",
        "    Args:\n",
        "        dataloader (torch.utils.data.DataLoader):\n",
        "            The DataLoader providing batches of test or validation data.\n",
        "        model (torch.nn.Module):\n",
        "            The trained neural network model to evaluate.\n",
        "        loss_fn (torch.nn.Module or callable):\n",
        "            The loss function used to compute the evaluation loss.\n",
        "\n",
        "    Returns:\n",
        "        float: The average loss over all test batches.\n",
        "\n",
        "    Prints:\n",
        "        Accuracy (% of correct predictions) and average test loss.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()                    # set the model to evaluation mode for best practices\n",
        "\n",
        "    size        = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "\n",
        "            X = X.to(device)                     # send data to the GPU device (if available)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return test_loss, 100*correct\n"
      ],
      "metadata": {
        "id": "V4Equ7KOus7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: prepare the DataLoader and select your optimizer and set the parameters for learning the model from DataLoader\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "mlp_model = SimpleCNNv1() ## model Class name here\n",
        "mlp_model.to(device)      ## device should have been determined earlier (at top of notebook)\n",
        "learning_rate = 0.001\n",
        "batch_size_val = 64\n",
        "epochs = 10\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(mlp_model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size_val)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size_val)\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "test_losses  = []\n",
        "train_accuracy = []\n",
        "test_accuracy  = []\n",
        "start_time   = time.time()\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    avg_train_loss, train_acc = train_loop(train_dataloader, mlp_model, loss_fn, optimizer)\n",
        "    avg_test_loss, test_acc  = test_loop(test_dataloader, mlp_model, loss_fn)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    test_losses.append(avg_test_loss)\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "print(\"Total fine-tuning time: %.3f sec\" %( (time.time()-start_time)) )\n",
        "print(\"Total fine-tuning time: %.3f hrs\" %( (time.time()-start_time)/3600) )\n",
        "\n",
        "print(mlp_model.__class__.__name__, \" model has been trained!\")\n"
      ],
      "metadata": {
        "id": "rHJfDg1puyHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######\n",
        "# visualizing the accuracy curves\n",
        "plt.plot(range(1,epochs+1), train_accuracy)\n",
        "plt.plot(range(1,epochs+1), test_accuracy)\n",
        "plt.title('Model accuracy after each epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Next5vqtu7Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "# Accuracy\n",
        "plt.figure()\n",
        "plt.plot(epochs, history[\"train_acc\"], label=\"Train accuracy\")\n",
        "plt.plot(epochs, history[\"test_acc\"],  label=\"Test accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# (Optional) Loss\n",
        "plt.figure()\n",
        "plt.plot(epochs, history[\"train_loss\"], label=\"Train loss\")\n",
        "plt.plot(epochs, history[\"test_loss\"],  label=\"Test loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs. Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vFR0myma1VJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now with a trained model.... let's see how well it does on a few specific examples:\n",
        "\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "test_dataloader  = DataLoader(test_data,         batch_size=128,        shuffle=False) # for testing/inference: it is not necessary to shuffle\n",
        "# we need to load data a batch at a time -- loading all of the data in memory is not efficient (or even possible sometimes)\n",
        "\n",
        "test_inputs, test_labels = next(iter(test_dataloader)) # returns a batch of 128 train-images and train-labels\n",
        "\n",
        "mlp_model.eval() # puts model into evaluation mode (training = False)\n",
        "images_shown = 24\n",
        "\n",
        "X_batch, y_batch = next(iter(test_dataloader)) # returns a batch of 128 train-images and train-labels\n",
        "X_batch = X_batch.to(device)\n",
        "y_batch = y_batch.to(device)\n",
        "\n",
        "test_inputs, test_labels = next(iter(test_dataloader)) # returns a batch of 128 train-images and train-labels\n",
        "test_inputs = test_inputs.to(device) #make sure we are on the same device (GPU or CPU)\n",
        "test_labels = test_labels.to(device)\n",
        "\n",
        "# run a forward pass -- no need to compute gradients\n",
        "with torch.no_grad():\n",
        "    logits = mlp_model(X_batch)\n",
        "\n",
        "# what are the predictions?\n",
        "preds = logits.argmax(dim=1)\n",
        "\n",
        "# plot values in a grid\n",
        "plt.figure(figsize=(10,6))\n",
        "for i in range(images_shown):\n",
        "    ax = plt.subplot(3, 8, i+1)\n",
        "    plt.imshow(test_inputs[i].cpu().squeeze(), cmap=\"gray\", interpolation=\"nearest\")\n",
        "    title = f\"P: {labels_map[int(preds[i])]}\"\n",
        "    if preds[i] == test_labels[i]:\n",
        "        title += \" ✓\"\n",
        "    else:\n",
        "        title += f\" ✗ (T: {labels_map[int(test_labels[i])]})\"\n",
        "    ax.set_title(title, fontsize=8)\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6nkFhyZIwLeS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}