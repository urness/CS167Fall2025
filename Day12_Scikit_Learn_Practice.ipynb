{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm/2dz9odm5HI/iZI+w3+A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urness/CS167Fall2025/blob/main/Day12_Scikit_Learn_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day12\n",
        "##Scikit Learn Practice\n",
        "\n",
        "#### CS167: Machine Learning, Fall 2025\n"
      ],
      "metadata": {
        "id": "8TmDLmOfqmAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of the Scikit Learn 'Algorithm':\n",
        "\n",
        "When working in Scikit Learn (`sklearn`), there is a general pattern that we can follow to implement any supported machine learning algorithm.\n",
        "\n",
        "It goes like this:\n",
        "1. Load your data using `pd.read_csv()`\n",
        "2. Split your data `train_test_split()`\n",
        "3. Create your classifier/regressor object\n",
        "4. Call `fit()` to train your model\n",
        "5. Call `predict()` to get predictions\n",
        "6. Call a metric function to measure the performance of your model."
      ],
      "metadata": {
        "id": "EUznYUEXS90v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "00UWYEjFTVpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classic scikit-learn algorithm\n",
        "\n",
        "#0. import libraries\n",
        "import sklearn\n",
        "import pandas\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import neighbors\n",
        "\n",
        "#1. load data\n",
        "iris_df = pandas.read_csv(\"/content/drive/MyDrive/CS167/datasets/irisData.csv\")\n",
        "\n",
        "#2. split data\n",
        "predictors = ['sepal length', 'sepal width','petal length', 'petal width']\n",
        "target = \"species\"\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "        train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "#3. Create classifier/regressor object\n",
        "dt = tree.DecisionTreeClassifier(random_state=2)\n",
        "\n",
        "#4. Call fit (to train the classification/regression model)\n",
        "dt.fit(train_data,train_sln)\n",
        "\n",
        "#5. Call predict to generate predictions\n",
        "iris_predictions = dt.predict(test_data)\n",
        "\n",
        "#6. Call a metric function to measure performance\n",
        "print(\"Accuracy:\", metrics.accuracy_score(test_sln,iris_predictions))\n",
        "\n",
        "# Show the acutal and predicted (this isn't necessary, but may help catch bugs)\n",
        "# print(\"___PREDICTED___ \\t  ___ACTUAL___\")\n",
        "# for i in range(len(test_sln)):\n",
        "#     print(iris_predictions[i],\"\\t\\t\", test_sln.iloc[i])\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "#print out a confusion matrix\n",
        "iris_labels= [\"Iris-setosa\", \"Iris-versicolor\",\"Iris-virginica\"]\n",
        "conf_mat = metrics.confusion_matrix(test_sln, iris_predictions, labels=iris_labels)\n",
        "print(pandas.DataFrame(conf_mat,index = iris_labels, columns = iris_labels))"
      ],
      "metadata": {
        "id": "nas9BvJ1TZBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Plotting Decision Trees\n",
        "\n",
        "You can use `matplotlib` to plot decision trees using the `sklearn.tree.plot_tree` method."
      ],
      "metadata": {
        "id": "eHj9RLsAp6KI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing decision tree using tree.plot_tree()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10)) # Makes it so the graph isn't tiny\n",
        "tree.plot_tree(dt); #if you remove the ;, you'll get more information about the tree"
      ],
      "metadata": {
        "id": "1o6oJ9tlp-MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tweak paramters to make it pretty\n",
        "import matplotlib.pyplot as plt\n",
        "fn=['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)']\n",
        "cn=['setosa', 'versicolor', 'virginica']\n",
        "plt.figure(figsize=(10,10))\n",
        "tree.plot_tree(dt, feature_names=fn, class_names=cn, filled=True);"
      ],
      "metadata": {
        "id": "SNfdNv8vrWjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing using `StandardScaler`\n",
        "\n",
        "**Documentation**: [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n"
      ],
      "metadata": {
        "id": "UD398wr6wBPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "G8drMsEfwaBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the training data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(train_data)\n",
        "\n",
        "train_data_normalized = scaler.transform(train_data)\n",
        "test_data_normalized = scaler.transform(test_data)"
      ],
      "metadata": {
        "id": "Y8Og6kkBwcox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of Scikit Learn with normalized data"
      ],
      "metadata": {
        "id": "i-5aSkesw_2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. load data\n",
        "iris_df = pandas.read_csv(\"/content/drive/MyDrive/CS167/datasets/irisData.csv\")\n",
        "\n",
        "#2A. split data\n",
        "predictors = ['sepal length', 'sepal width','petal length', 'petal width']\n",
        "target = \"species\"\n",
        "train_data, test_data, train_sln, test_sln = \\\n",
        "        train_test_split(iris_df[predictors], iris_df[target], test_size = 0.2, random_state=41)\n",
        "\n",
        "#2B. Normalize the training data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_data)\n",
        "train_data_normalized = scaler.transform(train_data)\n",
        "test_data_normalized = scaler.transform(test_data)\n",
        "\n",
        "#3. Create classifier/regressor object\n",
        "dt = tree.DecisionTreeClassifier(random_state=2)\n",
        "\n",
        "#4. Call fit (to train the classification/regression model)\n",
        "dt.fit(train_data_normalized,train_sln)\n",
        "\n",
        "#5. Call predict to generate predictions\n",
        "iris_predictions = dt.predict(test_data_normalized)\n",
        "\n",
        "#6. Call a metric function to measure performance\n",
        "print(\"Accuracy:\", metrics.accuracy_score(test_sln,iris_predictions))"
      ],
      "metadata": {
        "id": "KY8Q1C-dxLMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion Question:\n",
        "Why didnâ€™t normalize the data improve the accuracy in the previous example?\n"
      ],
      "metadata": {
        "id": "Nxkvu2qlypIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Dummy Variables"
      ],
      "metadata": {
        "id": "Lb-PJhY7l43A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pandas.read_csv(\"/content/drive/MyDrive/CS167/datasets/titanic.csv\")\n",
        "titanic_subset = titanic_df[[\"survived\", \"age\", \"fare\", \"embarked\"]].copy()\n",
        "titanic_subset.head(6)"
      ],
      "metadata": {
        "id": "JOBxrB5Ll8mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This isn't a good idea...\n",
        "titanic_subset[\"embarked\"] = titanic_subset[\"embarked\"].map({\"S\": 0, \"Q\": 1, \"C\": 2})\n",
        "titanic_subset.head(6)"
      ],
      "metadata": {
        "id": "iQhlyYA1nrlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instead, use dummy variables\n",
        "titanic_subset2= titanic_df[[\"survived\", \"age\", \"fare\", \"embarked\"]].copy()\n",
        "titanic_subset_with_dummies = pandas.get_dummies(titanic_subset2, columns=[\"embarked\"])\n",
        "titanic_subset_with_dummies.head(6)"
      ],
      "metadata": {
        "id": "IJa-ew-A4kGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¬ Exercise #1:\n",
        "\n",
        "1. Using the Iris dataset, build a knn (try using [`sklearn.neighbors.kNeighborsClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) and use it on the Iris Dataset\n",
        "    - in the call to `train_test_split` use `random_state=41`\n",
        "    - don't normalize the data (for this exercise)\n",
        "    - step #3 should look like, `neigh = neighbors.KNeighborsClassifier()`\n",
        "    - is there a difference in performance between using a **weighted** or **unweighted** knn?\n",
        "      - *hint: consider the parameter `weights` in the documentation.*\n",
        "    - what if you change the number of nearest neighbors to 21?"
      ],
      "metadata": {
        "id": "13LXK1seB6WK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #2:\n",
        "## Let's try regression now:\n",
        "\n",
        "Using the `vehicles.csv` dataset, let's try out sklearn with regression:\n",
        "- load the data, get the right subset\n",
        "- set predictors and target variables\n",
        "- use `train_test_split()` to split the data"
      ],
      "metadata": {
        "id": "JEYxK6ttCHb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#1. load data; get the right subset\n",
        "vehicles_df = pandas.read_csv(\"/content/drive/MyDrive/CS167/datasets/vehicles.csv\")\n",
        "gas_vehicles = vehicles_df[vehicles_df['fuelType']=='Regular'][['year', 'cylinders', 'displ', 'comb08']]\n",
        "gas_vehicles.dropna(inplace=True)\n",
        "\n",
        "#2. split the data\n",
        "# set the predictor variables and target variable\n",
        "predictors= ['year', 'cylinders', 'displ']\n",
        "target= 'comb08'\n",
        "train_data, test_data, train_sln, test_sln = train_test_split(gas_vehicles[predictors], gas_vehicles[target], test_size = 0.2, random_state=41)"
      ],
      "metadata": {
        "id": "RQhK9qo1pprK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And then do the next steps:\n",
        "\n",
        "- build our model using [`sklearn.neighbors.kNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
        "- fit our model using `fit()` and passing in `train_data` and `train_sln`\n",
        "- get our predictions by calling `predict()`\n",
        "- evaluate our predictions using `metrics.mean_squared_error()`, and `metrics.r2_score()`"
      ],
      "metadata": {
        "id": "9lIFZK0uXccz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "#3. Create classifier/regressor object\n",
        "\n",
        "#4. Call fit (to train the classification/regression model)\n",
        "\n",
        "#5. Call predict to generate predictions\n",
        "\n",
        "#6. Call a metric function to measure performance\n",
        "# use a metric to see how good our predictions are\n",
        "#print(\"R2: \", metrics.r2_score(test_sln, preds))\n",
        "#print(\"MAE: \", metrics.mean_absolute_error(test_sln, preds))\n",
        "#print(\"MSE: \", metrics.mean_squared_error(test_sln, preds))"
      ],
      "metadata": {
        "id": "0RREOeRSXku7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise #3:\n",
        "Use [`sklearn.preprocessing.StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) to **first** normalize the data, and then apply kNN Regression.\n",
        "- How does this effect the results?\n",
        "- Can you explain these results?"
      ],
      "metadata": {
        "id": "BTJ76nAUgIaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’¬ Exercise #4:\n",
        "Look up an appropriate Decision Tree algorithm and apply it to the vehicles data:\n",
        "- https://scikit-learn.org/stable/api/sklearn.tree.html\n",
        "- Using Default values of the decision tree, what is the $R^2$ metric?\n",
        "- Interpret the $R^2$ value... is it good or bad?"
      ],
      "metadata": {
        "id": "sw5Q4vDsc0dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #5:\n",
        "Change your decision tree to have a `max_depth` of 3.\n",
        "- does this help or hurt the decision tree performance?\n",
        "\n",
        "Compare your decision tree to a kNN algorithm:\n",
        "- what values of k seem to help the performance?\n",
        "- What else can you do to help the performance?\n",
        "\n",
        "Can you get a higher $R^2$ valuue using a knn algorithm or a decision tree?\n",
        "- what does this indicate about the data?"
      ],
      "metadata": {
        "id": "M5cF3HRddeFk"
      }
    }
  ]
}